{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying ML to neurodevelopmental discorders detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "\n",
    "from problem import get_cv\n",
    "from problem import get_all_data\n",
    "from problem import split_data\n",
    "from download_data import fetch_fmri_time_series\n",
    "\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn import preprocessing\n",
    "from sklearn.preprocessing import StandardScaler, FunctionTransformer\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, roc_curve\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.utils.multiclass import unique_labels\n",
    "\n",
    "from nilearn.connectome import ConnectivityMeasure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, labels = get_all_data()\n",
    "data_train, labels_train, data_test, labels_test = split_data(data, labels)\n",
    "data_abide=data[data['participants_dataset']=='abide']\n",
    "data_adhd=data[data['participants_dataset']=='adhd200']\n",
    "labels_adhd=labels[0:521]\n",
    "labels_abide=labels[521:1671]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluations functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def evaluation(X, y):\n",
    "    pipe = make_pipeline(FeatureExtractor(), Classifier())\n",
    "    cv = get_cv(X, y)\n",
    "    results = cross_validate(pipe, X, y, scoring=('roc_auc', 'accuracy'), cv=cv,\n",
    "                             verbose=1, return_train_score=True,\n",
    "                             n_jobs=1)\n",
    "    \n",
    "    return results\n",
    "\n",
    "#Validation on new data\n",
    "def evaluation_vv(X_train, y_train, X_test, y_test):\n",
    "    pipe = make_pipeline(FeatureExtractor(), Classifier())\n",
    "    clf = pipe.fit(X_train, y_train)\n",
    "    y_pred_train = clf.predict(X_train)\n",
    "    y_pred_test = clf.predict(X_test)\n",
    "    accuracy_train = accuracy_score(y_train, y_pred_train)\n",
    "    roc_auc_train = roc_auc_score(y_train, y_pred_train)\n",
    "    accuracy_test = accuracy_score(y_test, y_pred_test)\n",
    "    roc_auc_test = roc_auc_score(y_test, y_pred_test)\n",
    "    return accuracy_train, roc_auc_train, accuracy_test, roc_auc_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Only anatomical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X_df, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X_df):\n",
    "        # get only the anatomical information\n",
    "        X = X_df[[col for col in X_df.columns if col.startswith('anatomy')]]\n",
    "        return X.drop(columns='anatomy_select')\n",
    "    \n",
    "class Classifier(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.clf = make_pipeline(StandardScaler(), LogisticRegression(solver='lbfgs', max_iter=500))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.clf.fit(X, y)\n",
    "        self.classes_ = unique_labels(y)\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.8s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.6s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset              Train                  Test\n",
      "               ROC-AUC | Accuracy    ROC-AUC | Accuracy\n",
      "ADHD+ABIDE     0.800     0.726       0.661     0.632\n",
      "ABIDE          0.763     0.700       0.495     0.486\n",
      "ADHD           0.942     0.873       0.621     0.606\n",
      "ABIDE on ADHD  0.675     0.677       0.464     0.482\n",
      "ADHD on ABIDE  0.808     0.831       0.473     0.486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.4s finished\n"
     ]
    }
   ],
   "source": [
    "results_anat = evaluation(data, labels)\n",
    "results_anat_abide = evaluation(data_abide, labels_abide)\n",
    "results_anat_adhd = evaluation(data_adhd, labels_adhd)\n",
    "results_anat_abide_adhd = evaluation_vv(data_abide, labels_abide, data_adhd, labels_adhd)\n",
    "results_anat_adhd_abide = evaluation_vv(data_adhd, labels_adhd, data_abide, labels_abide)\n",
    "\n",
    "\n",
    "print('Dataset              Train                  Test')\n",
    "print('               ROC-AUC | Accuracy    ROC-AUC | Accuracy')\n",
    "print(\"ADHD+ABIDE     {:.3f}     {:.3f}       {:.3f}     {:.3f}\".format(np.mean(results_anat['train_roc_auc']), np.mean(results_anat['train_accuracy']), np.mean(results_anat['test_roc_auc']), np.mean(results_anat['test_accuracy'])))\n",
    "print(\"ABIDE          {:.3f}     {:.3f}       {:.3f}     {:.3f}\".format(np.mean(results_anat_abide['train_roc_auc']), np.mean(results_anat_abide['train_accuracy']), np.mean(results_anat_abide['test_roc_auc']), np.mean(results_anat_abide['test_accuracy'])))\n",
    "print(\"ADHD           {:.3f}     {:.3f}       {:.3f}     {:.3f}\".format(np.mean(results_anat_adhd['train_roc_auc']), np.mean(results_anat_adhd['train_accuracy']), np.mean(results_anat_adhd['test_roc_auc']), np.mean(results_anat_adhd['test_accuracy'])))\n",
    "print(\"ABIDE on ADHD  {:.3f}     {:.3f}       {:.3f}     {:.3f}\".format(np.mean(results_anat_abide_adhd[1]), np.mean(results_anat_abide_adhd[0]), np.mean(results_anat_abide_adhd[3]), np.mean(results_anat_abide_adhd[2])))\n",
    "print(\"ADHD on ABIDE  {:.3f}     {:.3f}       {:.3f}     {:.3f}\".format(np.mean(results_anat_adhd_abide[1]), np.mean(results_anat_adhd_abide[0]), np.mean(results_anat_adhd_abide[3]), np.mean(results_anat_adhd_abide[2])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## fMRI-derived features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_fmri(fmri_filenames):\n",
    "    \"\"\"Load time-series extracted from the fMRI using a specific atlas.\"\"\"\n",
    "    return np.array([pd.read_csv(subject_filename,\n",
    "                                 header=None).values\n",
    "                     for subject_filename in fmri_filenames])\n",
    "\n",
    "\n",
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        # make a transformer which will load the time series and compute the\n",
    "        # connectome matrix\n",
    "        self.transformer_fmri = make_pipeline(\n",
    "            FunctionTransformer(func=_load_fmri, validate=False),\n",
    "            ConnectivityMeasure(kind='tangent', vectorize=True))\n",
    "        \n",
    "    def fit(self, X_df, y):\n",
    "        # get only the time series for the MSDL atlas\n",
    "        fmri_filenames = X_df['fmri_msdl']\n",
    "        self.transformer_fmri.fit(fmri_filenames, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X_df):\n",
    "        fmri_filenames = X_df['fmri_msdl']\n",
    "        return self.transformer_fmri.transform(fmri_filenames)\n",
    "\n",
    "class Classifier(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.clf = make_pipeline(StandardScaler(), LogisticRegression(C=1.))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.clf.fit(X, y)\n",
    "        self.classes_ = unique_labels(y)\n",
    "        return self\n",
    "       \n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.clf.predict_proba(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  3.1min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   58.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     Train                  Test\n",
      "               ROC-AUC | Accuracy    ROC-AUC | Accuracy\n",
      "ADHD+ABIDE     1.000     1.000       0.596     0.596\n",
      "ABIDE          1.000     1.000       0.612     0.612\n",
      "ADHD           1.000     1.000       0.623     0.623\n",
      "ABIDE on ADHD  1.000     1.000       0.571     0.619\n",
      "ADHD on ABIDE  1.000     1.000       0.520     0.530\n"
     ]
    }
   ],
   "source": [
    "results_anat = evaluation(data, labels)\n",
    "results_anat_abide = evaluation(data_abide, labels_abide)\n",
    "results_anat_adhd = evaluation(data_adhd, labels_adhd)\n",
    "results_anat_abide_adhd = evaluation_vv(data_abide, labels_abide, data_adhd, labels_adhd)\n",
    "results_anat_adhd_abide = evaluation_vv(data_adhd, labels_adhd, data_abide, labels_abide)\n",
    "\n",
    "\n",
    "print('Dataset              Train                  Test')\n",
    "print('               ROC-AUC | Accuracy    ROC-AUC | Accuracy')\n",
    "print(\"ADHD+ABIDE     {:.3f}     {:.3f}       {:.3f}     {:.3f}\".format(np.mean(results_anat['train_roc_auc']), np.mean(results_anat['train_accuracy']), np.mean(results_anat['test_roc_auc']), np.mean(results_anat['test_accuracy'])))\n",
    "print(\"ABIDE          {:.3f}     {:.3f}       {:.3f}     {:.3f}\".format(np.mean(results_anat_abide['train_roc_auc']), np.mean(results_anat_abide['train_accuracy']), np.mean(results_anat_abide['test_roc_auc']), np.mean(results_anat_abide['test_accuracy'])))\n",
    "print(\"ADHD           {:.3f}     {:.3f}       {:.3f}     {:.3f}\".format(np.mean(results_anat_adhd['train_roc_auc']), np.mean(results_anat_adhd['train_accuracy']), np.mean(results_anat_adhd['test_roc_auc']), np.mean(results_anat_adhd['test_accuracy'])))\n",
    "print(\"ABIDE on ADHD  {:.3f}     {:.3f}       {:.3f}     {:.3f}\".format(np.mean(results_anat_abide_adhd[1]), np.mean(results_anat_abide_adhd[0]), np.mean(results_anat_abide_adhd[3]), np.mean(results_anat_abide_adhd[2])))\n",
    "print(\"ADHD on ABIDE  {:.3f}     {:.3f}       {:.3f}     {:.3f}\".format(np.mean(results_anat_adhd_abide[1]), np.mean(results_anat_adhd_abide[0]), np.mean(results_anat_adhd_abide[3]), np.mean(results_anat_adhd_abide[2])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combining anatomy and fMRI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_fmri(fmri_filenames):\n",
    "    \"\"\"Load time-series extracted from the fMRI using a specific atlas.\"\"\"\n",
    "    return np.array([pd.read_csv(subject_filename,\n",
    "                                 header=None).values\n",
    "                     for subject_filename in fmri_filenames])\n",
    "\n",
    "\n",
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        # make a transformer which will load the time series and compute the\n",
    "        # connectome matrix\n",
    "        self.transformer_fmri = make_pipeline(\n",
    "            FunctionTransformer(func=_load_fmri, validate=False),\n",
    "            ConnectivityMeasure(kind='tangent', vectorize=True))\n",
    "    \n",
    "    def fit(self, X_df, y):\n",
    "        fmri_filenames = X_df['fmri_msdl']\n",
    "        self.transformer_fmri.fit(fmri_filenames, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X_df):\n",
    "        fmri_filenames = X_df['fmri_msdl']\n",
    "        X_connectome = self.transformer_fmri.transform(fmri_filenames)\n",
    "        X_connectome = pd.DataFrame(X_connectome, index=X_df.index)\n",
    "        X_connectome.columns = ['connectome_{}'.format(i)\n",
    "                                for i in range(X_connectome.columns.size)]\n",
    "        # get the anatomical information\n",
    "        X_anatomy = X_df[[col for col in X_df.columns\n",
    "                          if col.startswith('anatomy')]]\n",
    "        X_anatomy = X_anatomy.drop(columns='anatomy_select')\n",
    "        # concatenate both matrices\n",
    "        return pd.concat([X_connectome, X_anatomy], axis=1)\n",
    "\n",
    "class Classifier(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.clf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.clf.fit(X, y)\n",
    "        self.classes_ = unique_labels(y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.clf.predict_proba(X)\n",
    "\n",
    "class Classifier(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.clf_connectome = make_pipeline(StandardScaler(),\n",
    "                                            LogisticRegression(C=1.))\n",
    "        self.clf_anatomy = make_pipeline(StandardScaler(),\n",
    "                                         LogisticRegression(C=1.))\n",
    "        self.meta_clf = LogisticRegression(C=1.)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X_anatomy = X[[col for col in X.columns if col.startswith('anatomy')]]\n",
    "        X_connectome = X[[col for col in X.columns\n",
    "                          if col.startswith('connectome')]]\n",
    "        train_idx, validation_idx = train_test_split(range(y.size),\n",
    "                                                     test_size=0.33,\n",
    "                                                     shuffle=True,\n",
    "                                                     random_state=42)\n",
    "        X_anatomy_train = X_anatomy.iloc[train_idx]\n",
    "        X_anatomy_validation = X_anatomy.iloc[validation_idx]\n",
    "        X_connectome_train = X_connectome.iloc[train_idx]\n",
    "        X_connectome_validation = X_connectome.iloc[validation_idx]\n",
    "        y_train = y[train_idx]\n",
    "        y_validation = y[validation_idx]\n",
    "\n",
    "        self.clf_connectome.fit(X_connectome_train, y_train)\n",
    "        self.clf_anatomy.fit(X_anatomy_train, y_train)\n",
    "\n",
    "        y_connectome_pred = self.clf_connectome.predict_proba(\n",
    "            X_connectome_validation)\n",
    "        y_anatomy_pred = self.clf_anatomy.predict_proba(\n",
    "            X_anatomy_validation)\n",
    "\n",
    "        self.meta_clf.fit(\n",
    "            np.concatenate([y_connectome_pred, y_anatomy_pred], axis=1),\n",
    "            y_validation)\n",
    "        self.classes_ = unique_labels(y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_anatomy = X[[col for col in X.columns if col.startswith('anatomy')]]\n",
    "        X_connectome = X[[col for col in X.columns\n",
    "                          if col.startswith('connectome')]]\n",
    "\n",
    "        y_anatomy_pred = self.clf_anatomy.predict_proba(X_anatomy)\n",
    "        y_connectome_pred = self.clf_connectome.predict_proba(X_connectome)\n",
    "\n",
    "        return self.meta_clf.predict(\n",
    "            np.concatenate([y_connectome_pred, y_anatomy_pred], axis=1))\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X_anatomy = X[[col for col in X.columns if col.startswith('anatomy')]]\n",
    "        X_connectome = X[[col for col in X.columns\n",
    "                          if col.startswith('connectome')]]\n",
    "\n",
    "        y_anatomy_pred = self.clf_anatomy.predict_proba(X_anatomy)\n",
    "        y_connectome_pred = self.clf_connectome.predict_proba(X_connectome)\n",
    "\n",
    "        return self.meta_clf.predict_proba(\n",
    "            np.concatenate([y_connectome_pred, y_anatomy_pred], axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  3.3min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  2.2min finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  1.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset              Train                  Test\n",
      "               ROC-AUC | Accuracy    ROC-AUC | Accuracy\n",
      "ADHD+ABIDE     0.893     0.811       0.662     0.662\n",
      "ABIDE          0.915     0.855       0.649     0.649\n",
      "ADHD           0.918     0.730       0.598     0.598\n",
      "ABIDE on ADHD  0.808     0.810       0.547     0.595\n",
      "ADHD on ABIDE  0.615     0.721       0.506     0.529\n"
     ]
    }
   ],
   "source": [
    "results_anat = evaluation(data, labels)\n",
    "results_anat_abide = evaluation(data_abide, labels_abide)\n",
    "results_anat_adhd = evaluation(data_adhd, labels_adhd)\n",
    "results_anat_abide_adhd = evaluation_vv(data_abide, labels_abide, data_adhd, labels_adhd)\n",
    "results_anat_adhd_abide = evaluation_vv(data_adhd, labels_adhd, data_abide, labels_abide)\n",
    "\n",
    "\n",
    "print('Dataset              Train                  Test')\n",
    "print('               ROC-AUC | Accuracy    ROC-AUC | Accuracy')\n",
    "print(\"ADHD+ABIDE     {:.3f}     {:.3f}       {:.3f}     {:.3f}\".format(np.mean(results_anat['train_roc_auc']), np.mean(results_anat['train_accuracy']), np.mean(results_anat['test_roc_auc']), np.mean(results_anat['test_accuracy'])))\n",
    "print(\"ABIDE          {:.3f}     {:.3f}       {:.3f}     {:.3f}\".format(np.mean(results_anat_abide['train_roc_auc']), np.mean(results_anat_abide['train_accuracy']), np.mean(results_anat_abide['test_roc_auc']), np.mean(results_anat_abide['test_accuracy'])))\n",
    "print(\"ADHD           {:.3f}     {:.3f}       {:.3f}     {:.3f}\".format(np.mean(results_anat_adhd['train_roc_auc']), np.mean(results_anat_adhd['train_accuracy']), np.mean(results_anat_adhd['test_roc_auc']), np.mean(results_anat_adhd['test_accuracy'])))\n",
    "print(\"ABIDE on ADHD  {:.3f}     {:.3f}       {:.3f}     {:.3f}\".format(np.mean(results_anat_abide_adhd[1]), np.mean(results_anat_abide_adhd[0]), np.mean(results_anat_abide_adhd[3]), np.mean(results_anat_abide_adhd[2])))\n",
    "print(\"ADHD on ABIDE  {:.3f}     {:.3f}       {:.3f}     {:.3f}\".format(np.mean(results_anat_adhd_abide[1]), np.mean(results_anat_adhd_abide[0]), np.mean(results_anat_adhd_abide[3]), np.mean(results_anat_adhd_abide[2])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "ATLAS = ('msdl', 'basc064', 'basc122', 'basc197','harvard_oxford_cort_prob_2mm', 'craddock_scorr_mean','power_2011')\n",
    "\n",
    "def _load_fmri(fmri_filenames):\n",
    "    return np.array([\n",
    "        pd.read_csv(subject_filename, header=None).values\n",
    "        for subject_filename in fmri_filenames\n",
    "    ])\n",
    "\n",
    "\n",
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.transformer_fmri_dict = {\n",
    "            key: make_pipeline(\n",
    "                FunctionTransformer(func=_load_fmri, validate=False),\n",
    "                ConnectivityMeasure(kind='tangent', vectorize=True))\n",
    "            for key in ATLAS\n",
    "        }\n",
    "\n",
    "    def fit(self, X_df, y):\n",
    "        for atlas_name in self.transformer_fmri_dict.keys():\n",
    "            atlas_col_name = 'fmri_' + atlas_name\n",
    "            fmri_filename = X_df[atlas_col_name]\n",
    "            self.transformer_fmri_dict[atlas_name].fit(fmri_filename, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X_df):\n",
    "        X_anatomy = X_df[[\n",
    "            col for col in X_df.columns if col.startswith('anatomy')\n",
    "        ]]\n",
    "        X_anatomy = X_anatomy.drop(columns='anatomy_select')\n",
    "\n",
    "        X_anatomy_column = X_anatomy.columns\n",
    "        X_anatomy_index = X_df.index\n",
    "\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        X_anatomy_data = min_max_scaler.fit_transform(X_anatomy)\n",
    "        X_anatomy = pd.DataFrame(\n",
    "            data=X_anatomy_data,\n",
    "            index=X_anatomy_index,\n",
    "            columns=X_anatomy_column)\n",
    "\n",
    "        X_atlas_df = pd.DataFrame(index=X_df.index)\n",
    "        for atlas_name in self.transformer_fmri_dict.keys():\n",
    "            atlas_col_name = 'fmri_' + atlas_name\n",
    "            fmri_filename = X_df[atlas_col_name]\n",
    "\n",
    "            X_connectome = self.transformer_fmri_dict[atlas_name].transform(\n",
    "                fmri_filename)\n",
    "            X_connectome = pd.DataFrame(X_connectome, index=X_df.index)\n",
    "            X_connectome.columns = [\n",
    "                atlas_name + '_connectome_{}'.format(i)\n",
    "                for i in range(X_connectome.columns.size)\n",
    "            ]\n",
    "\n",
    "            X_anatomy.columns = [\n",
    "                atlas_name + '_' + col for col in X_anatomy_column\n",
    "            ]\n",
    "\n",
    "            X_atlas_df = pd.concat([X_atlas_df, X_anatomy, X_connectome],\n",
    "                                   axis=1)\n",
    "\n",
    "        return X_atlas_df\n",
    "\n",
    "ATLAS = ('msdl', 'basc064', 'basc122', 'basc197','harvard_oxford_cort_prob_2mm', 'craddock_scorr_mean','power_2011')\n",
    "\n",
    "class Classifier(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.base_clf_dict = {key: SVC(probability=True) for key in ATLAS}\n",
    "        self.clf = LogisticRegression(C=1.)\n",
    "        self.svc_parameters = [{\n",
    "            'kernel': ['rbf'],\n",
    "            'gamma': [1e-3, 1e-4],\n",
    "            'C': [0.5, 1, 10, 100, 1000]\n",
    "        }, {\n",
    "            'kernel': ['linear'],\n",
    "            'C': [0.5, 1, 10, 100, 1000]\n",
    "        }]\n",
    "\n",
    "    def _clf_data(self, X):\n",
    "        X_atlas_dict = {\n",
    "            key: X[[col for col in X.columns if col.startswith(key)]].values\n",
    "            for key in ATLAS\n",
    "        }\n",
    "        X_meta_clf = None\n",
    "        for key in self.base_clf_dict.keys():\n",
    "            base_predict_pro = self.base_clf_dict[key].predict_proba(\n",
    "                X_atlas_dict[key])\n",
    "\n",
    "            if X_meta_clf is None:\n",
    "                X_meta_clf = base_predict_pro\n",
    "            else:\n",
    "                X_meta_clf = np.concatenate([X_meta_clf, base_predict_pro],\n",
    "                                            axis=1)\n",
    "\n",
    "        return X_meta_clf\n",
    "\n",
    "    def _grid_search(self, estimator, parameters, X, y):\n",
    "        grid_search = GridSearchCV(estimator, parameters, n_jobs=-1, verbose=1)\n",
    "        grid_search.fit(X, y)\n",
    "\n",
    "        return grid_search.best_params_\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X_atlas_dict = {\n",
    "            key: X[[col for col in X.columns if col.startswith(key)]].values\n",
    "            for key in ATLAS\n",
    "        }\n",
    "        for key, val in X_atlas_dict.items():\n",
    "            best_params = self._grid_search(self.base_clf_dict[key],\n",
    "                                            self.svc_parameters, val, y)\n",
    "            self.base_clf_dict[key].set_params(**best_params)\n",
    "\n",
    "            self.base_clf_dict[key].fit(val, y)\n",
    "\n",
    "        X_clf = self._clf_data(X)\n",
    "        self.clf.fit(X_clf, y)\n",
    "        self.classes_ = unique_labels(y)\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_clf = self._clf_data(X)\n",
    "\n",
    "        return self.clf.predict(X_clf)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X_clf = self._clf_data(X)\n",
    "\n",
    "        return self.clf.predict_proba(X_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results_anat = evaluation(data, labels)\n",
    "results_anat_abide = evaluation(data_abide, labels_abide)\n",
    "results_anat_adhd = evaluation(data_adhd, labels_adhd)\n",
    "results_anat_abide_adhd = evaluation_vv(data_abide, labels_abide, data_adhd, labels_adhd)\n",
    "results_anat_adhd_abide = evaluation_vv(data_adhd, labels_adhd, data_abide, labels_abide)\n",
    "\n",
    "\n",
    "print('Dataset              Train                  Test')\n",
    "print('               ROC-AUC | Accuracy    ROC-AUC | Accuracy')\n",
    "print(\"ADHD+ABIDE     {:.3f}     {:.3f}       {:.3f}     {:.3f}\".format(np.mean(results_anat['train_roc_auc']), np.mean(results_anat['train_accuracy']), np.mean(results_anat['test_roc_auc']), np.mean(results_anat['test_accuracy'])))\n",
    "print(\"ABIDE          {:.3f}     {:.3f}       {:.3f}     {:.3f}\".format(np.mean(results_anat_abide['train_roc_auc']), np.mean(results_anat_abide['train_accuracy']), np.mean(results_anat_abide['test_roc_auc']), np.mean(results_anat_abide['test_accuracy'])))\n",
    "print(\"ADHD           {:.3f}     {:.3f}       {:.3f}     {:.3f}\".format(np.mean(results_anat_adhd['train_roc_auc']), np.mean(results_anat_adhd['train_accuracy']), np.mean(results_anat_adhd['test_roc_auc']), np.mean(results_anat_adhd['test_accuracy'])))\n",
    "print(\"ABIDE on ADHD  {:.3f}     {:.3f}       {:.3f}     {:.3f}\".format(np.mean(results_anat_abide_adhd[1]), np.mean(results_anat_abide_adhd[0]), np.mean(results_anat_abide_adhd[3]), np.mean(results_anat_abide_adhd[2])))\n",
    "print(\"ADHD on ABIDE  {:.3f}     {:.3f}       {:.3f}     {:.3f}\".format(np.mean(results_anat_adhd_abide[1]), np.mean(results_anat_adhd_abide[0]), np.mean(results_anat_adhd_abide[3]), np.mean(results_anat_adhd_abide[2])))\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
