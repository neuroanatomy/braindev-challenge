{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style=\"text-align: left;\">\n",
    "<table style=\"width:100%; background-color:transparent;\">\n",
    "  <tr style=\"background-color:transparent;\">\n",
    "    <td style=\"background-color:transparent;\">[<img src=\"http://project.inria.fr/saclaycds/files/2017/02/logoUPSayPlusCDS_990.png\" width=\"70%\">](http://www.datascience-paris-saclay.fr)</td>\n",
    "    <td style=\"background-color:transparent;\">[<img src=\"https://paris-saclay-cds.github.io/autism_challenge/images/institut_pasteur_logo.svg\" width=\"30%\">](https://research.pasteur.fr/en/team/group-roberto-toro/)</td>\n",
    "  </tr>\n",
    "</table> \n",
    "</div>\n",
    "\n",
    "<center><h1>IMaging-PsychiAtry Challenge (IMPAC): Predicting neurodevelopmental disorders from MRI data\n",
    "</h1></center>\n",
    "\n",
    "<center><h3>A data challenge on Neurodevelopmental disorders detection</h3></center>\n",
    "<br/>\n",
    "<center>_Roberto Toro (Institut Pasteur), Nicolas Traut (Institut Pasteur), Anita Beggiato (Institut Pasteur), Katja Heuer (Institut Pasteur),<br /> Gael Varoquaux (Inria, Parietal), Alex Gramfort (Inria, Parietal), Balazs Kegl (LAL),<br /> Guillaume Lemaitre (CDS), Alexandre Boucaud (CDS), and Joris van den Bossche (CDS)_</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Software prerequisites"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This starting kit requires the following dependencies:\n",
    "\n",
    "* `numpy`\n",
    "* `scipy`\n",
    "* `pandas`\n",
    "* `scikit-learn`\n",
    "* `matplolib`\n",
    "* `seaborn`\n",
    "* `nilearn`\n",
    "* `jupyter`\n",
    "* `ramp-workflow`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by downloading the data from Internet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem import get_train_data\n",
    "\n",
    "data_train, labels_train = get_train_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participants_site</th>\n",
       "      <th>participants_sex</th>\n",
       "      <th>participants_age</th>\n",
       "      <th>participants_dataset</th>\n",
       "      <th>anatomy_lh_bankssts_area</th>\n",
       "      <th>anatomy_lh_caudalanteriorcingulate_area</th>\n",
       "      <th>anatomy_lh_caudalmiddlefrontal_area</th>\n",
       "      <th>anatomy_lh_cuneus_area</th>\n",
       "      <th>anatomy_lh_entorhinal_area</th>\n",
       "      <th>anatomy_lh_fusiform_area</th>\n",
       "      <th>...</th>\n",
       "      <th>fmri_basc064</th>\n",
       "      <th>fmri_basc122</th>\n",
       "      <th>fmri_basc197</th>\n",
       "      <th>fmri_craddock_scorr_mean</th>\n",
       "      <th>fmri_harvard_oxford_cort_prob_2mm</th>\n",
       "      <th>fmri_msdl</th>\n",
       "      <th>fmri_power_2011</th>\n",
       "      <th>fmri_motions</th>\n",
       "      <th>fmri_select</th>\n",
       "      <th>repetition_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adhd700021</th>\n",
       "      <td>204</td>\n",
       "      <td>F</td>\n",
       "      <td>11.17</td>\n",
       "      <td>adhd200</td>\n",
       "      <td>1124</td>\n",
       "      <td>743</td>\n",
       "      <td>2886</td>\n",
       "      <td>1535</td>\n",
       "      <td>589</td>\n",
       "      <td>3731</td>\n",
       "      <td>...</td>\n",
       "      <td>data/fmri_adhd/basc064/adhd700021/run_1/adhd70...</td>\n",
       "      <td>data/fmri_adhd/basc122/adhd700021/run_1/adhd70...</td>\n",
       "      <td>data/fmri_adhd/basc197/adhd700021/run_1/adhd70...</td>\n",
       "      <td>data/fmri_adhd/craddock_scorr_mean/adhd700021/...</td>\n",
       "      <td>data/fmri_adhd/harvard_oxford_cort_prob_2mm/ad...</td>\n",
       "      <td>data/fmri_adhd/msdl/adhd700021/run_1/adhd70002...</td>\n",
       "      <td>data/fmri_adhd/power_2011/adhd700021/run_1/adh...</td>\n",
       "      <td>data/fmri_adhd/motions/adhd700021/run_1/motion...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adhd242402</th>\n",
       "      <td>204</td>\n",
       "      <td>F</td>\n",
       "      <td>13.24</td>\n",
       "      <td>adhd200</td>\n",
       "      <td>1039</td>\n",
       "      <td>595</td>\n",
       "      <td>1966</td>\n",
       "      <td>1568</td>\n",
       "      <td>411</td>\n",
       "      <td>2769</td>\n",
       "      <td>...</td>\n",
       "      <td>data/fmri_adhd/basc064/adhd242402/run_1/adhd24...</td>\n",
       "      <td>data/fmri_adhd/basc122/adhd242402/run_1/adhd24...</td>\n",
       "      <td>data/fmri_adhd/basc197/adhd242402/run_1/adhd24...</td>\n",
       "      <td>data/fmri_adhd/craddock_scorr_mean/adhd242402/...</td>\n",
       "      <td>data/fmri_adhd/harvard_oxford_cort_prob_2mm/ad...</td>\n",
       "      <td>data/fmri_adhd/msdl/adhd242402/run_1/adhd24240...</td>\n",
       "      <td>data/fmri_adhd/power_2011/adhd242402/run_1/adh...</td>\n",
       "      <td>data/fmri_adhd/motions/adhd242402/run_1/motion...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adhd972340</th>\n",
       "      <td>204</td>\n",
       "      <td>F</td>\n",
       "      <td>13.75</td>\n",
       "      <td>adhd200</td>\n",
       "      <td>601</td>\n",
       "      <td>492</td>\n",
       "      <td>1554</td>\n",
       "      <td>1345</td>\n",
       "      <td>455</td>\n",
       "      <td>2452</td>\n",
       "      <td>...</td>\n",
       "      <td>data/fmri_adhd/basc064/adhd972340/run_1/adhd97...</td>\n",
       "      <td>data/fmri_adhd/basc122/adhd972340/run_1/adhd97...</td>\n",
       "      <td>data/fmri_adhd/basc197/adhd972340/run_1/adhd97...</td>\n",
       "      <td>data/fmri_adhd/craddock_scorr_mean/adhd972340/...</td>\n",
       "      <td>data/fmri_adhd/harvard_oxford_cort_prob_2mm/ad...</td>\n",
       "      <td>data/fmri_adhd/msdl/adhd972340/run_1/adhd97234...</td>\n",
       "      <td>data/fmri_adhd/power_2011/adhd972340/run_1/adh...</td>\n",
       "      <td>data/fmri_adhd/motions/adhd972340/run_1/motion...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adhd055645</th>\n",
       "      <td>204</td>\n",
       "      <td>F</td>\n",
       "      <td>11.18</td>\n",
       "      <td>adhd200</td>\n",
       "      <td>699</td>\n",
       "      <td>521</td>\n",
       "      <td>1773</td>\n",
       "      <td>1251</td>\n",
       "      <td>341</td>\n",
       "      <td>2628</td>\n",
       "      <td>...</td>\n",
       "      <td>data/fmri_adhd/basc064/adhd055645/run_1/adhd05...</td>\n",
       "      <td>data/fmri_adhd/basc122/adhd055645/run_1/adhd05...</td>\n",
       "      <td>data/fmri_adhd/basc197/adhd055645/run_1/adhd05...</td>\n",
       "      <td>data/fmri_adhd/craddock_scorr_mean/adhd055645/...</td>\n",
       "      <td>data/fmri_adhd/harvard_oxford_cort_prob_2mm/ad...</td>\n",
       "      <td>data/fmri_adhd/msdl/adhd055645/run_1/adhd05564...</td>\n",
       "      <td>data/fmri_adhd/power_2011/adhd055645/run_1/adh...</td>\n",
       "      <td>data/fmri_adhd/motions/adhd055645/run_1/motion...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adhd436785</th>\n",
       "      <td>204</td>\n",
       "      <td>F</td>\n",
       "      <td>11.41</td>\n",
       "      <td>adhd200</td>\n",
       "      <td>799</td>\n",
       "      <td>605</td>\n",
       "      <td>2564</td>\n",
       "      <td>1688</td>\n",
       "      <td>419</td>\n",
       "      <td>2508</td>\n",
       "      <td>...</td>\n",
       "      <td>data/fmri_adhd/basc064/adhd436785/run_1/adhd43...</td>\n",
       "      <td>data/fmri_adhd/basc122/adhd436785/run_1/adhd43...</td>\n",
       "      <td>data/fmri_adhd/basc197/adhd436785/run_1/adhd43...</td>\n",
       "      <td>data/fmri_adhd/craddock_scorr_mean/adhd436785/...</td>\n",
       "      <td>data/fmri_adhd/harvard_oxford_cort_prob_2mm/ad...</td>\n",
       "      <td>data/fmri_adhd/msdl/adhd436785/run_1/adhd43678...</td>\n",
       "      <td>data/fmri_adhd/power_2011/adhd436785/run_1/adh...</td>\n",
       "      <td>data/fmri_adhd/motions/adhd436785/run_1/motion...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 222 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            participants_site participants_sex  participants_age  \\\n",
       "subject_id                                                         \n",
       "adhd700021                204                F             11.17   \n",
       "adhd242402                204                F             13.24   \n",
       "adhd972340                204                F             13.75   \n",
       "adhd055645                204                F             11.18   \n",
       "adhd436785                204                F             11.41   \n",
       "\n",
       "           participants_dataset  anatomy_lh_bankssts_area  \\\n",
       "subject_id                                                  \n",
       "adhd700021              adhd200                      1124   \n",
       "adhd242402              adhd200                      1039   \n",
       "adhd972340              adhd200                       601   \n",
       "adhd055645              adhd200                       699   \n",
       "adhd436785              adhd200                       799   \n",
       "\n",
       "            anatomy_lh_caudalanteriorcingulate_area  \\\n",
       "subject_id                                            \n",
       "adhd700021                                      743   \n",
       "adhd242402                                      595   \n",
       "adhd972340                                      492   \n",
       "adhd055645                                      521   \n",
       "adhd436785                                      605   \n",
       "\n",
       "            anatomy_lh_caudalmiddlefrontal_area  anatomy_lh_cuneus_area  \\\n",
       "subject_id                                                                \n",
       "adhd700021                                 2886                    1535   \n",
       "adhd242402                                 1966                    1568   \n",
       "adhd972340                                 1554                    1345   \n",
       "adhd055645                                 1773                    1251   \n",
       "adhd436785                                 2564                    1688   \n",
       "\n",
       "            anatomy_lh_entorhinal_area  anatomy_lh_fusiform_area  ...  \\\n",
       "subject_id                                                        ...   \n",
       "adhd700021                         589                      3731  ...   \n",
       "adhd242402                         411                      2769  ...   \n",
       "adhd972340                         455                      2452  ...   \n",
       "adhd055645                         341                      2628  ...   \n",
       "adhd436785                         419                      2508  ...   \n",
       "\n",
       "                                                 fmri_basc064  \\\n",
       "subject_id                                                      \n",
       "adhd700021  data/fmri_adhd/basc064/adhd700021/run_1/adhd70...   \n",
       "adhd242402  data/fmri_adhd/basc064/adhd242402/run_1/adhd24...   \n",
       "adhd972340  data/fmri_adhd/basc064/adhd972340/run_1/adhd97...   \n",
       "adhd055645  data/fmri_adhd/basc064/adhd055645/run_1/adhd05...   \n",
       "adhd436785  data/fmri_adhd/basc064/adhd436785/run_1/adhd43...   \n",
       "\n",
       "                                                 fmri_basc122  \\\n",
       "subject_id                                                      \n",
       "adhd700021  data/fmri_adhd/basc122/adhd700021/run_1/adhd70...   \n",
       "adhd242402  data/fmri_adhd/basc122/adhd242402/run_1/adhd24...   \n",
       "adhd972340  data/fmri_adhd/basc122/adhd972340/run_1/adhd97...   \n",
       "adhd055645  data/fmri_adhd/basc122/adhd055645/run_1/adhd05...   \n",
       "adhd436785  data/fmri_adhd/basc122/adhd436785/run_1/adhd43...   \n",
       "\n",
       "                                                 fmri_basc197  \\\n",
       "subject_id                                                      \n",
       "adhd700021  data/fmri_adhd/basc197/adhd700021/run_1/adhd70...   \n",
       "adhd242402  data/fmri_adhd/basc197/adhd242402/run_1/adhd24...   \n",
       "adhd972340  data/fmri_adhd/basc197/adhd972340/run_1/adhd97...   \n",
       "adhd055645  data/fmri_adhd/basc197/adhd055645/run_1/adhd05...   \n",
       "adhd436785  data/fmri_adhd/basc197/adhd436785/run_1/adhd43...   \n",
       "\n",
       "                                     fmri_craddock_scorr_mean  \\\n",
       "subject_id                                                      \n",
       "adhd700021  data/fmri_adhd/craddock_scorr_mean/adhd700021/...   \n",
       "adhd242402  data/fmri_adhd/craddock_scorr_mean/adhd242402/...   \n",
       "adhd972340  data/fmri_adhd/craddock_scorr_mean/adhd972340/...   \n",
       "adhd055645  data/fmri_adhd/craddock_scorr_mean/adhd055645/...   \n",
       "adhd436785  data/fmri_adhd/craddock_scorr_mean/adhd436785/...   \n",
       "\n",
       "                            fmri_harvard_oxford_cort_prob_2mm  \\\n",
       "subject_id                                                      \n",
       "adhd700021  data/fmri_adhd/harvard_oxford_cort_prob_2mm/ad...   \n",
       "adhd242402  data/fmri_adhd/harvard_oxford_cort_prob_2mm/ad...   \n",
       "adhd972340  data/fmri_adhd/harvard_oxford_cort_prob_2mm/ad...   \n",
       "adhd055645  data/fmri_adhd/harvard_oxford_cort_prob_2mm/ad...   \n",
       "adhd436785  data/fmri_adhd/harvard_oxford_cort_prob_2mm/ad...   \n",
       "\n",
       "                                                    fmri_msdl  \\\n",
       "subject_id                                                      \n",
       "adhd700021  data/fmri_adhd/msdl/adhd700021/run_1/adhd70002...   \n",
       "adhd242402  data/fmri_adhd/msdl/adhd242402/run_1/adhd24240...   \n",
       "adhd972340  data/fmri_adhd/msdl/adhd972340/run_1/adhd97234...   \n",
       "adhd055645  data/fmri_adhd/msdl/adhd055645/run_1/adhd05564...   \n",
       "adhd436785  data/fmri_adhd/msdl/adhd436785/run_1/adhd43678...   \n",
       "\n",
       "                                              fmri_power_2011  \\\n",
       "subject_id                                                      \n",
       "adhd700021  data/fmri_adhd/power_2011/adhd700021/run_1/adh...   \n",
       "adhd242402  data/fmri_adhd/power_2011/adhd242402/run_1/adh...   \n",
       "adhd972340  data/fmri_adhd/power_2011/adhd972340/run_1/adh...   \n",
       "adhd055645  data/fmri_adhd/power_2011/adhd055645/run_1/adh...   \n",
       "adhd436785  data/fmri_adhd/power_2011/adhd436785/run_1/adh...   \n",
       "\n",
       "                                                 fmri_motions  fmri_select  \\\n",
       "subject_id                                                                   \n",
       "adhd700021  data/fmri_adhd/motions/adhd700021/run_1/motion...            1   \n",
       "adhd242402  data/fmri_adhd/motions/adhd242402/run_1/motion...            1   \n",
       "adhd972340  data/fmri_adhd/motions/adhd972340/run_1/motion...            1   \n",
       "adhd055645  data/fmri_adhd/motions/adhd055645/run_1/motion...            1   \n",
       "adhd436785  data/fmri_adhd/motions/adhd436785/run_1/motion...            1   \n",
       "\n",
       "            repetition_time  \n",
       "subject_id                   \n",
       "adhd700021              2.0  \n",
       "adhd242402              2.0  \n",
       "adhd972340              2.0  \n",
       "adhd055645              2.0  \n",
       "adhd436785              2.0  \n",
       "\n",
       "[5 rows x 222 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "abide      1127\n",
       "adhd200     506\n",
       "Name: participants_dataset, dtype: int64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train.participants_dataset.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "print(labels_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of subjects in the training tests: 1633\n"
     ]
    }
   ],
   "source": [
    "print('Number of subjects in the training tests: {}'.format(labels_train.size))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Participant features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participants_site</th>\n",
       "      <th>participants_sex</th>\n",
       "      <th>participants_age</th>\n",
       "      <th>participants_dataset</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adhd700021</th>\n",
       "      <td>204</td>\n",
       "      <td>F</td>\n",
       "      <td>11.17</td>\n",
       "      <td>adhd200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adhd242402</th>\n",
       "      <td>204</td>\n",
       "      <td>F</td>\n",
       "      <td>13.24</td>\n",
       "      <td>adhd200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adhd972340</th>\n",
       "      <td>204</td>\n",
       "      <td>F</td>\n",
       "      <td>13.75</td>\n",
       "      <td>adhd200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adhd055645</th>\n",
       "      <td>204</td>\n",
       "      <td>F</td>\n",
       "      <td>11.18</td>\n",
       "      <td>adhd200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adhd436785</th>\n",
       "      <td>204</td>\n",
       "      <td>F</td>\n",
       "      <td>11.41</td>\n",
       "      <td>adhd200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adhd823935</th>\n",
       "      <td>204</td>\n",
       "      <td>M</td>\n",
       "      <td>12.10</td>\n",
       "      <td>adhd200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adhd061873</th>\n",
       "      <td>204</td>\n",
       "      <td>F</td>\n",
       "      <td>9.16</td>\n",
       "      <td>adhd200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adhd181929</th>\n",
       "      <td>204</td>\n",
       "      <td>F</td>\n",
       "      <td>7.55</td>\n",
       "      <td>adhd200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adhd711427</th>\n",
       "      <td>204</td>\n",
       "      <td>M</td>\n",
       "      <td>11.21</td>\n",
       "      <td>adhd200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adhd447253</th>\n",
       "      <td>204</td>\n",
       "      <td>M</td>\n",
       "      <td>12.38</td>\n",
       "      <td>adhd200</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            participants_site participants_sex  participants_age  \\\n",
       "subject_id                                                         \n",
       "adhd700021                204                F             11.17   \n",
       "adhd242402                204                F             13.24   \n",
       "adhd972340                204                F             13.75   \n",
       "adhd055645                204                F             11.18   \n",
       "adhd436785                204                F             11.41   \n",
       "adhd823935                204                M             12.10   \n",
       "adhd061873                204                F              9.16   \n",
       "adhd181929                204                F              7.55   \n",
       "adhd711427                204                M             11.21   \n",
       "adhd447253                204                M             12.38   \n",
       "\n",
       "           participants_dataset  \n",
       "subject_id                       \n",
       "adhd700021              adhd200  \n",
       "adhd242402              adhd200  \n",
       "adhd972340              adhd200  \n",
       "adhd055645              adhd200  \n",
       "adhd436785              adhd200  \n",
       "adhd823935              adhd200  \n",
       "adhd061873              adhd200  \n",
       "adhd181929              adhd200  \n",
       "adhd711427              adhd200  \n",
       "adhd447253              adhd200  "
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_participants = data_train[[col for col in data_train.columns if col.startswith('participants')]]\n",
    "data_train_participants.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Structural MRI features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A set of structural features have been extracted for each subject: (i) normalized brain volume computed using subcortical segmentation of FreeSurfer and (ii) cortical thickness and area for right and left hemisphere of FreeSurfer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>anatomy_lh_bankssts_area</th>\n",
       "      <th>anatomy_lh_caudalanteriorcingulate_area</th>\n",
       "      <th>anatomy_lh_caudalmiddlefrontal_area</th>\n",
       "      <th>anatomy_lh_cuneus_area</th>\n",
       "      <th>anatomy_lh_entorhinal_area</th>\n",
       "      <th>anatomy_lh_fusiform_area</th>\n",
       "      <th>anatomy_lh_inferiorparietal_area</th>\n",
       "      <th>anatomy_lh_inferiortemporal_area</th>\n",
       "      <th>anatomy_lh_isthmuscingulate_area</th>\n",
       "      <th>anatomy_lh_lateraloccipital_area</th>\n",
       "      <th>...</th>\n",
       "      <th>anatomy_SupraTentorialVolNotVentVox</th>\n",
       "      <th>anatomy_MaskVol</th>\n",
       "      <th>anatomy_BrainSegVol.to.eTIV</th>\n",
       "      <th>anatomy_MaskVol.to.eTIV</th>\n",
       "      <th>anatomy_lhSurfaceHoles</th>\n",
       "      <th>anatomy_rhSurfaceHoles</th>\n",
       "      <th>anatomy_SurfaceHoles</th>\n",
       "      <th>anatomy_EstimatedTotalIntraCranialVol</th>\n",
       "      <th>anatomy_eTIV</th>\n",
       "      <th>anatomy_select</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adhd700021</th>\n",
       "      <td>1124</td>\n",
       "      <td>743</td>\n",
       "      <td>2886</td>\n",
       "      <td>1535</td>\n",
       "      <td>589</td>\n",
       "      <td>3731</td>\n",
       "      <td>4220</td>\n",
       "      <td>3491</td>\n",
       "      <td>890</td>\n",
       "      <td>4989</td>\n",
       "      <td>...</td>\n",
       "      <td>1034028</td>\n",
       "      <td>1544179</td>\n",
       "      <td>0.810540</td>\n",
       "      <td>1.055481</td>\n",
       "      <td>46</td>\n",
       "      <td>51</td>\n",
       "      <td>97</td>\n",
       "      <td>1.463009e+06</td>\n",
       "      <td>1.463009e+06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adhd242402</th>\n",
       "      <td>1039</td>\n",
       "      <td>595</td>\n",
       "      <td>1966</td>\n",
       "      <td>1568</td>\n",
       "      <td>411</td>\n",
       "      <td>2769</td>\n",
       "      <td>4235</td>\n",
       "      <td>2698</td>\n",
       "      <td>885</td>\n",
       "      <td>5246</td>\n",
       "      <td>...</td>\n",
       "      <td>942270</td>\n",
       "      <td>1413593</td>\n",
       "      <td>0.819411</td>\n",
       "      <td>1.071676</td>\n",
       "      <td>61</td>\n",
       "      <td>70</td>\n",
       "      <td>131</td>\n",
       "      <td>1.319049e+06</td>\n",
       "      <td>1.319049e+06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adhd972340</th>\n",
       "      <td>601</td>\n",
       "      <td>492</td>\n",
       "      <td>1554</td>\n",
       "      <td>1345</td>\n",
       "      <td>455</td>\n",
       "      <td>2452</td>\n",
       "      <td>3761</td>\n",
       "      <td>2273</td>\n",
       "      <td>837</td>\n",
       "      <td>3741</td>\n",
       "      <td>...</td>\n",
       "      <td>788484</td>\n",
       "      <td>1279934</td>\n",
       "      <td>0.769160</td>\n",
       "      <td>1.063212</td>\n",
       "      <td>91</td>\n",
       "      <td>61</td>\n",
       "      <td>152</td>\n",
       "      <td>1.203837e+06</td>\n",
       "      <td>1.203837e+06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adhd055645</th>\n",
       "      <td>699</td>\n",
       "      <td>521</td>\n",
       "      <td>1773</td>\n",
       "      <td>1251</td>\n",
       "      <td>341</td>\n",
       "      <td>2628</td>\n",
       "      <td>4026</td>\n",
       "      <td>2882</td>\n",
       "      <td>746</td>\n",
       "      <td>3951</td>\n",
       "      <td>...</td>\n",
       "      <td>823592</td>\n",
       "      <td>1303815</td>\n",
       "      <td>0.806114</td>\n",
       "      <td>1.079301</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>84</td>\n",
       "      <td>1.208018e+06</td>\n",
       "      <td>1.208018e+06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adhd436785</th>\n",
       "      <td>799</td>\n",
       "      <td>605</td>\n",
       "      <td>2564</td>\n",
       "      <td>1688</td>\n",
       "      <td>419</td>\n",
       "      <td>2508</td>\n",
       "      <td>5048</td>\n",
       "      <td>3616</td>\n",
       "      <td>1215</td>\n",
       "      <td>5496</td>\n",
       "      <td>...</td>\n",
       "      <td>1023783</td>\n",
       "      <td>1532056</td>\n",
       "      <td>0.843271</td>\n",
       "      <td>1.094796</td>\n",
       "      <td>59</td>\n",
       "      <td>81</td>\n",
       "      <td>140</td>\n",
       "      <td>1.399398e+06</td>\n",
       "      <td>1.399398e+06</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 208 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            anatomy_lh_bankssts_area  anatomy_lh_caudalanteriorcingulate_area  \\\n",
       "subject_id                                                                      \n",
       "adhd700021                      1124                                      743   \n",
       "adhd242402                      1039                                      595   \n",
       "adhd972340                       601                                      492   \n",
       "adhd055645                       699                                      521   \n",
       "adhd436785                       799                                      605   \n",
       "\n",
       "            anatomy_lh_caudalmiddlefrontal_area  anatomy_lh_cuneus_area  \\\n",
       "subject_id                                                                \n",
       "adhd700021                                 2886                    1535   \n",
       "adhd242402                                 1966                    1568   \n",
       "adhd972340                                 1554                    1345   \n",
       "adhd055645                                 1773                    1251   \n",
       "adhd436785                                 2564                    1688   \n",
       "\n",
       "            anatomy_lh_entorhinal_area  anatomy_lh_fusiform_area  \\\n",
       "subject_id                                                         \n",
       "adhd700021                         589                      3731   \n",
       "adhd242402                         411                      2769   \n",
       "adhd972340                         455                      2452   \n",
       "adhd055645                         341                      2628   \n",
       "adhd436785                         419                      2508   \n",
       "\n",
       "            anatomy_lh_inferiorparietal_area  \\\n",
       "subject_id                                     \n",
       "adhd700021                              4220   \n",
       "adhd242402                              4235   \n",
       "adhd972340                              3761   \n",
       "adhd055645                              4026   \n",
       "adhd436785                              5048   \n",
       "\n",
       "            anatomy_lh_inferiortemporal_area  \\\n",
       "subject_id                                     \n",
       "adhd700021                              3491   \n",
       "adhd242402                              2698   \n",
       "adhd972340                              2273   \n",
       "adhd055645                              2882   \n",
       "adhd436785                              3616   \n",
       "\n",
       "            anatomy_lh_isthmuscingulate_area  \\\n",
       "subject_id                                     \n",
       "adhd700021                               890   \n",
       "adhd242402                               885   \n",
       "adhd972340                               837   \n",
       "adhd055645                               746   \n",
       "adhd436785                              1215   \n",
       "\n",
       "            anatomy_lh_lateraloccipital_area  ...  \\\n",
       "subject_id                                    ...   \n",
       "adhd700021                              4989  ...   \n",
       "adhd242402                              5246  ...   \n",
       "adhd972340                              3741  ...   \n",
       "adhd055645                              3951  ...   \n",
       "adhd436785                              5496  ...   \n",
       "\n",
       "            anatomy_SupraTentorialVolNotVentVox  anatomy_MaskVol  \\\n",
       "subject_id                                                         \n",
       "adhd700021                              1034028          1544179   \n",
       "adhd242402                               942270          1413593   \n",
       "adhd972340                               788484          1279934   \n",
       "adhd055645                               823592          1303815   \n",
       "adhd436785                              1023783          1532056   \n",
       "\n",
       "            anatomy_BrainSegVol.to.eTIV  anatomy_MaskVol.to.eTIV  \\\n",
       "subject_id                                                         \n",
       "adhd700021                     0.810540                 1.055481   \n",
       "adhd242402                     0.819411                 1.071676   \n",
       "adhd972340                     0.769160                 1.063212   \n",
       "adhd055645                     0.806114                 1.079301   \n",
       "adhd436785                     0.843271                 1.094796   \n",
       "\n",
       "            anatomy_lhSurfaceHoles  anatomy_rhSurfaceHoles  \\\n",
       "subject_id                                                   \n",
       "adhd700021                      46                      51   \n",
       "adhd242402                      61                      70   \n",
       "adhd972340                      91                      61   \n",
       "adhd055645                      42                      42   \n",
       "adhd436785                      59                      81   \n",
       "\n",
       "            anatomy_SurfaceHoles  anatomy_EstimatedTotalIntraCranialVol  \\\n",
       "subject_id                                                                \n",
       "adhd700021                    97                           1.463009e+06   \n",
       "adhd242402                   131                           1.319049e+06   \n",
       "adhd972340                   152                           1.203837e+06   \n",
       "adhd055645                    84                           1.208018e+06   \n",
       "adhd436785                   140                           1.399398e+06   \n",
       "\n",
       "            anatomy_eTIV  anatomy_select  \n",
       "subject_id                                \n",
       "adhd700021  1.463009e+06               1  \n",
       "adhd242402  1.319049e+06               1  \n",
       "adhd972340  1.203837e+06               1  \n",
       "adhd055645  1.208018e+06               1  \n",
       "adhd436785  1.399398e+06               1  \n",
       "\n",
       "[5 rows x 208 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_anatomy = data_train[[col for col in data_train.columns if col.startswith('anatomy')]]\n",
    "data_train_anatomy.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that the column `anatomy_select` contain a label affected during a manual quality check (i.e. `0` and `3` reject, `1` accept, `2` accept with reserve). This column can be used during training to exclude noisy data for instance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject_id\n",
       "adhd700021    1\n",
       "adhd242402    1\n",
       "adhd972340    1\n",
       "adhd055645    1\n",
       "adhd436785    1\n",
       "Name: anatomy_select, dtype: int64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_anatomy['anatomy_select'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functional MRI features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/preprocessing_fmri.png\" width=\"40%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The original data acquired are resting-state functional MRI. Each subject also comes with fMRI signals extracted on different brain parcellations and atlases, and a set of confound signals. Those brain atlases and parcellations are: (i) BASC parcellations with 64, 122, and 197 regions (Bellec 2010), (ii) Ncuts parcellations (Craddock 2012), (iii) Harvard-Oxford anatomical parcellations, (iv) MSDL functional atlas (Varoquaux 2011), and (v) Power atlas (Power 2011). The script used for this extraction can be found [there](https://github.com/ramp-kits/autism/blob/master/preprocessing/extract_time_series.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fmri_basc064</th>\n",
       "      <th>fmri_basc122</th>\n",
       "      <th>fmri_basc197</th>\n",
       "      <th>fmri_craddock_scorr_mean</th>\n",
       "      <th>fmri_harvard_oxford_cort_prob_2mm</th>\n",
       "      <th>fmri_msdl</th>\n",
       "      <th>fmri_power_2011</th>\n",
       "      <th>fmri_motions</th>\n",
       "      <th>fmri_select</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adhd700021</th>\n",
       "      <td>data/fmri_adhd/basc064/adhd700021/run_1/adhd70...</td>\n",
       "      <td>data/fmri_adhd/basc122/adhd700021/run_1/adhd70...</td>\n",
       "      <td>data/fmri_adhd/basc197/adhd700021/run_1/adhd70...</td>\n",
       "      <td>data/fmri_adhd/craddock_scorr_mean/adhd700021/...</td>\n",
       "      <td>data/fmri_adhd/harvard_oxford_cort_prob_2mm/ad...</td>\n",
       "      <td>data/fmri_adhd/msdl/adhd700021/run_1/adhd70002...</td>\n",
       "      <td>data/fmri_adhd/power_2011/adhd700021/run_1/adh...</td>\n",
       "      <td>data/fmri_adhd/motions/adhd700021/run_1/motion...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adhd242402</th>\n",
       "      <td>data/fmri_adhd/basc064/adhd242402/run_1/adhd24...</td>\n",
       "      <td>data/fmri_adhd/basc122/adhd242402/run_1/adhd24...</td>\n",
       "      <td>data/fmri_adhd/basc197/adhd242402/run_1/adhd24...</td>\n",
       "      <td>data/fmri_adhd/craddock_scorr_mean/adhd242402/...</td>\n",
       "      <td>data/fmri_adhd/harvard_oxford_cort_prob_2mm/ad...</td>\n",
       "      <td>data/fmri_adhd/msdl/adhd242402/run_1/adhd24240...</td>\n",
       "      <td>data/fmri_adhd/power_2011/adhd242402/run_1/adh...</td>\n",
       "      <td>data/fmri_adhd/motions/adhd242402/run_1/motion...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adhd972340</th>\n",
       "      <td>data/fmri_adhd/basc064/adhd972340/run_1/adhd97...</td>\n",
       "      <td>data/fmri_adhd/basc122/adhd972340/run_1/adhd97...</td>\n",
       "      <td>data/fmri_adhd/basc197/adhd972340/run_1/adhd97...</td>\n",
       "      <td>data/fmri_adhd/craddock_scorr_mean/adhd972340/...</td>\n",
       "      <td>data/fmri_adhd/harvard_oxford_cort_prob_2mm/ad...</td>\n",
       "      <td>data/fmri_adhd/msdl/adhd972340/run_1/adhd97234...</td>\n",
       "      <td>data/fmri_adhd/power_2011/adhd972340/run_1/adh...</td>\n",
       "      <td>data/fmri_adhd/motions/adhd972340/run_1/motion...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adhd055645</th>\n",
       "      <td>data/fmri_adhd/basc064/adhd055645/run_1/adhd05...</td>\n",
       "      <td>data/fmri_adhd/basc122/adhd055645/run_1/adhd05...</td>\n",
       "      <td>data/fmri_adhd/basc197/adhd055645/run_1/adhd05...</td>\n",
       "      <td>data/fmri_adhd/craddock_scorr_mean/adhd055645/...</td>\n",
       "      <td>data/fmri_adhd/harvard_oxford_cort_prob_2mm/ad...</td>\n",
       "      <td>data/fmri_adhd/msdl/adhd055645/run_1/adhd05564...</td>\n",
       "      <td>data/fmri_adhd/power_2011/adhd055645/run_1/adh...</td>\n",
       "      <td>data/fmri_adhd/motions/adhd055645/run_1/motion...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adhd436785</th>\n",
       "      <td>data/fmri_adhd/basc064/adhd436785/run_1/adhd43...</td>\n",
       "      <td>data/fmri_adhd/basc122/adhd436785/run_1/adhd43...</td>\n",
       "      <td>data/fmri_adhd/basc197/adhd436785/run_1/adhd43...</td>\n",
       "      <td>data/fmri_adhd/craddock_scorr_mean/adhd436785/...</td>\n",
       "      <td>data/fmri_adhd/harvard_oxford_cort_prob_2mm/ad...</td>\n",
       "      <td>data/fmri_adhd/msdl/adhd436785/run_1/adhd43678...</td>\n",
       "      <td>data/fmri_adhd/power_2011/adhd436785/run_1/adh...</td>\n",
       "      <td>data/fmri_adhd/motions/adhd436785/run_1/motion...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 fmri_basc064  \\\n",
       "subject_id                                                      \n",
       "adhd700021  data/fmri_adhd/basc064/adhd700021/run_1/adhd70...   \n",
       "adhd242402  data/fmri_adhd/basc064/adhd242402/run_1/adhd24...   \n",
       "adhd972340  data/fmri_adhd/basc064/adhd972340/run_1/adhd97...   \n",
       "adhd055645  data/fmri_adhd/basc064/adhd055645/run_1/adhd05...   \n",
       "adhd436785  data/fmri_adhd/basc064/adhd436785/run_1/adhd43...   \n",
       "\n",
       "                                                 fmri_basc122  \\\n",
       "subject_id                                                      \n",
       "adhd700021  data/fmri_adhd/basc122/adhd700021/run_1/adhd70...   \n",
       "adhd242402  data/fmri_adhd/basc122/adhd242402/run_1/adhd24...   \n",
       "adhd972340  data/fmri_adhd/basc122/adhd972340/run_1/adhd97...   \n",
       "adhd055645  data/fmri_adhd/basc122/adhd055645/run_1/adhd05...   \n",
       "adhd436785  data/fmri_adhd/basc122/adhd436785/run_1/adhd43...   \n",
       "\n",
       "                                                 fmri_basc197  \\\n",
       "subject_id                                                      \n",
       "adhd700021  data/fmri_adhd/basc197/adhd700021/run_1/adhd70...   \n",
       "adhd242402  data/fmri_adhd/basc197/adhd242402/run_1/adhd24...   \n",
       "adhd972340  data/fmri_adhd/basc197/adhd972340/run_1/adhd97...   \n",
       "adhd055645  data/fmri_adhd/basc197/adhd055645/run_1/adhd05...   \n",
       "adhd436785  data/fmri_adhd/basc197/adhd436785/run_1/adhd43...   \n",
       "\n",
       "                                     fmri_craddock_scorr_mean  \\\n",
       "subject_id                                                      \n",
       "adhd700021  data/fmri_adhd/craddock_scorr_mean/adhd700021/...   \n",
       "adhd242402  data/fmri_adhd/craddock_scorr_mean/adhd242402/...   \n",
       "adhd972340  data/fmri_adhd/craddock_scorr_mean/adhd972340/...   \n",
       "adhd055645  data/fmri_adhd/craddock_scorr_mean/adhd055645/...   \n",
       "adhd436785  data/fmri_adhd/craddock_scorr_mean/adhd436785/...   \n",
       "\n",
       "                            fmri_harvard_oxford_cort_prob_2mm  \\\n",
       "subject_id                                                      \n",
       "adhd700021  data/fmri_adhd/harvard_oxford_cort_prob_2mm/ad...   \n",
       "adhd242402  data/fmri_adhd/harvard_oxford_cort_prob_2mm/ad...   \n",
       "adhd972340  data/fmri_adhd/harvard_oxford_cort_prob_2mm/ad...   \n",
       "adhd055645  data/fmri_adhd/harvard_oxford_cort_prob_2mm/ad...   \n",
       "adhd436785  data/fmri_adhd/harvard_oxford_cort_prob_2mm/ad...   \n",
       "\n",
       "                                                    fmri_msdl  \\\n",
       "subject_id                                                      \n",
       "adhd700021  data/fmri_adhd/msdl/adhd700021/run_1/adhd70002...   \n",
       "adhd242402  data/fmri_adhd/msdl/adhd242402/run_1/adhd24240...   \n",
       "adhd972340  data/fmri_adhd/msdl/adhd972340/run_1/adhd97234...   \n",
       "adhd055645  data/fmri_adhd/msdl/adhd055645/run_1/adhd05564...   \n",
       "adhd436785  data/fmri_adhd/msdl/adhd436785/run_1/adhd43678...   \n",
       "\n",
       "                                              fmri_power_2011  \\\n",
       "subject_id                                                      \n",
       "adhd700021  data/fmri_adhd/power_2011/adhd700021/run_1/adh...   \n",
       "adhd242402  data/fmri_adhd/power_2011/adhd242402/run_1/adh...   \n",
       "adhd972340  data/fmri_adhd/power_2011/adhd972340/run_1/adh...   \n",
       "adhd055645  data/fmri_adhd/power_2011/adhd055645/run_1/adh...   \n",
       "adhd436785  data/fmri_adhd/power_2011/adhd436785/run_1/adh...   \n",
       "\n",
       "                                                 fmri_motions  fmri_select  \n",
       "subject_id                                                                  \n",
       "adhd700021  data/fmri_adhd/motions/adhd700021/run_1/motion...            1  \n",
       "adhd242402  data/fmri_adhd/motions/adhd242402/run_1/motion...            1  \n",
       "adhd972340  data/fmri_adhd/motions/adhd972340/run_1/motion...            1  \n",
       "adhd055645  data/fmri_adhd/motions/adhd055645/run_1/motion...            1  \n",
       "adhd436785  data/fmri_adhd/motions/adhd436785/run_1/motion...            1  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_functional = data_train[[col for col in data_train.columns if col.startswith('fmri')]]\n",
    "data_train_functional.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unlike the anatomical and participants data, the available data are filename to CSV files in which the time-series information are stored. We show in the next section how to read and extract meaningful information from those data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Similarly to the anatomical data, the column `fmri_select` gives information about the manual quality check."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "subject_id\n",
       "adhd700021    1\n",
       "adhd242402    1\n",
       "adhd972340    1\n",
       "adhd055645    1\n",
       "adhd436785    1\n",
       "Name: fmri_select, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train_functional['fmri_select'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The testing data can be loaded similarly as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "from problem import get_test_data\n",
    "\n",
    "data_test, labels_test = get_test_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>participants_site</th>\n",
       "      <th>participants_sex</th>\n",
       "      <th>participants_age</th>\n",
       "      <th>participants_dataset</th>\n",
       "      <th>anatomy_lh_bankssts_area</th>\n",
       "      <th>anatomy_lh_caudalanteriorcingulate_area</th>\n",
       "      <th>anatomy_lh_caudalmiddlefrontal_area</th>\n",
       "      <th>anatomy_lh_cuneus_area</th>\n",
       "      <th>anatomy_lh_entorhinal_area</th>\n",
       "      <th>anatomy_lh_fusiform_area</th>\n",
       "      <th>...</th>\n",
       "      <th>fmri_basc064</th>\n",
       "      <th>fmri_basc122</th>\n",
       "      <th>fmri_basc197</th>\n",
       "      <th>fmri_craddock_scorr_mean</th>\n",
       "      <th>fmri_harvard_oxford_cort_prob_2mm</th>\n",
       "      <th>fmri_msdl</th>\n",
       "      <th>fmri_power_2011</th>\n",
       "      <th>fmri_motions</th>\n",
       "      <th>fmri_select</th>\n",
       "      <th>repetition_time</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>subject_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>adhd317934</th>\n",
       "      <td>207</td>\n",
       "      <td>M</td>\n",
       "      <td>13.33</td>\n",
       "      <td>adhd200</td>\n",
       "      <td>1215</td>\n",
       "      <td>592</td>\n",
       "      <td>3205</td>\n",
       "      <td>2045</td>\n",
       "      <td>508</td>\n",
       "      <td>3996</td>\n",
       "      <td>...</td>\n",
       "      <td>data/fmri_adhd/basc064/adhd317934/run_1/adhd31...</td>\n",
       "      <td>data/fmri_adhd/basc122/adhd317934/run_1/adhd31...</td>\n",
       "      <td>data/fmri_adhd/basc197/adhd317934/run_1/adhd31...</td>\n",
       "      <td>data/fmri_adhd/craddock_scorr_mean/adhd317934/...</td>\n",
       "      <td>data/fmri_adhd/harvard_oxford_cort_prob_2mm/ad...</td>\n",
       "      <td>data/fmri_adhd/msdl/adhd317934/run_1/adhd31793...</td>\n",
       "      <td>data/fmri_adhd/power_2011/adhd317934/run_1/adh...</td>\n",
       "      <td>data/fmri_adhd/motions/adhd317934/run_1/motion...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adhd291243</th>\n",
       "      <td>206</td>\n",
       "      <td>F</td>\n",
       "      <td>11.75</td>\n",
       "      <td>adhd200</td>\n",
       "      <td>942</td>\n",
       "      <td>641</td>\n",
       "      <td>2372</td>\n",
       "      <td>1452</td>\n",
       "      <td>414</td>\n",
       "      <td>2777</td>\n",
       "      <td>...</td>\n",
       "      <td>data/fmri_adhd/basc064/adhd291243/run_1/adhd29...</td>\n",
       "      <td>data/fmri_adhd/basc122/adhd291243/run_1/adhd29...</td>\n",
       "      <td>data/fmri_adhd/basc197/adhd291243/run_1/adhd29...</td>\n",
       "      <td>data/fmri_adhd/craddock_scorr_mean/adhd291243/...</td>\n",
       "      <td>data/fmri_adhd/harvard_oxford_cort_prob_2mm/ad...</td>\n",
       "      <td>data/fmri_adhd/msdl/adhd291243/run_1/adhd29124...</td>\n",
       "      <td>data/fmri_adhd/power_2011/adhd291243/run_1/adh...</td>\n",
       "      <td>data/fmri_adhd/motions/adhd291243/run_1/motion...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adhd484859</th>\n",
       "      <td>201</td>\n",
       "      <td>F</td>\n",
       "      <td>13.67</td>\n",
       "      <td>adhd200</td>\n",
       "      <td>1255</td>\n",
       "      <td>865</td>\n",
       "      <td>2446</td>\n",
       "      <td>1339</td>\n",
       "      <td>446</td>\n",
       "      <td>3449</td>\n",
       "      <td>...</td>\n",
       "      <td>data/fmri_adhd/basc064/adhd484859/run_1/adhd48...</td>\n",
       "      <td>data/fmri_adhd/basc122/adhd484859/run_1/adhd48...</td>\n",
       "      <td>data/fmri_adhd/basc197/adhd484859/run_1/adhd48...</td>\n",
       "      <td>data/fmri_adhd/craddock_scorr_mean/adhd484859/...</td>\n",
       "      <td>data/fmri_adhd/harvard_oxford_cort_prob_2mm/ad...</td>\n",
       "      <td>data/fmri_adhd/msdl/adhd484859/run_1/adhd48485...</td>\n",
       "      <td>data/fmri_adhd/power_2011/adhd484859/run_1/adh...</td>\n",
       "      <td>data/fmri_adhd/motions/adhd484859/run_1/motion...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adhd570109</th>\n",
       "      <td>206</td>\n",
       "      <td>F</td>\n",
       "      <td>12.75</td>\n",
       "      <td>adhd200</td>\n",
       "      <td>1029</td>\n",
       "      <td>501</td>\n",
       "      <td>2413</td>\n",
       "      <td>1625</td>\n",
       "      <td>499</td>\n",
       "      <td>3197</td>\n",
       "      <td>...</td>\n",
       "      <td>data/fmri_adhd/basc064/adhd570109/run_1/adhd57...</td>\n",
       "      <td>data/fmri_adhd/basc122/adhd570109/run_1/adhd57...</td>\n",
       "      <td>data/fmri_adhd/basc197/adhd570109/run_1/adhd57...</td>\n",
       "      <td>data/fmri_adhd/craddock_scorr_mean/adhd570109/...</td>\n",
       "      <td>data/fmri_adhd/harvard_oxford_cort_prob_2mm/ad...</td>\n",
       "      <td>data/fmri_adhd/msdl/adhd570109/run_1/adhd57010...</td>\n",
       "      <td>data/fmri_adhd/power_2011/adhd570109/run_1/adh...</td>\n",
       "      <td>data/fmri_adhd/motions/adhd570109/run_1/motion...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adhd053509</th>\n",
       "      <td>205</td>\n",
       "      <td>F</td>\n",
       "      <td>9.08</td>\n",
       "      <td>adhd200</td>\n",
       "      <td>1242</td>\n",
       "      <td>606</td>\n",
       "      <td>2423</td>\n",
       "      <td>1640</td>\n",
       "      <td>487</td>\n",
       "      <td>3149</td>\n",
       "      <td>...</td>\n",
       "      <td>data/fmri_adhd/basc064/adhd053509/run_1/adhd05...</td>\n",
       "      <td>data/fmri_adhd/basc122/adhd053509/run_1/adhd05...</td>\n",
       "      <td>data/fmri_adhd/basc197/adhd053509/run_1/adhd05...</td>\n",
       "      <td>data/fmri_adhd/craddock_scorr_mean/adhd053509/...</td>\n",
       "      <td>data/fmri_adhd/harvard_oxford_cort_prob_2mm/ad...</td>\n",
       "      <td>data/fmri_adhd/msdl/adhd053509/run_1/adhd05350...</td>\n",
       "      <td>data/fmri_adhd/power_2011/adhd053509/run_1/adh...</td>\n",
       "      <td>data/fmri_adhd/motions/adhd053509/run_1/motion...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 222 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            participants_site participants_sex  participants_age  \\\n",
       "subject_id                                                         \n",
       "adhd317934                207                M             13.33   \n",
       "adhd291243                206                F             11.75   \n",
       "adhd484859                201                F             13.67   \n",
       "adhd570109                206                F             12.75   \n",
       "adhd053509                205                F              9.08   \n",
       "\n",
       "           participants_dataset  anatomy_lh_bankssts_area  \\\n",
       "subject_id                                                  \n",
       "adhd317934              adhd200                      1215   \n",
       "adhd291243              adhd200                       942   \n",
       "adhd484859              adhd200                      1255   \n",
       "adhd570109              adhd200                      1029   \n",
       "adhd053509              adhd200                      1242   \n",
       "\n",
       "            anatomy_lh_caudalanteriorcingulate_area  \\\n",
       "subject_id                                            \n",
       "adhd317934                                      592   \n",
       "adhd291243                                      641   \n",
       "adhd484859                                      865   \n",
       "adhd570109                                      501   \n",
       "adhd053509                                      606   \n",
       "\n",
       "            anatomy_lh_caudalmiddlefrontal_area  anatomy_lh_cuneus_area  \\\n",
       "subject_id                                                                \n",
       "adhd317934                                 3205                    2045   \n",
       "adhd291243                                 2372                    1452   \n",
       "adhd484859                                 2446                    1339   \n",
       "adhd570109                                 2413                    1625   \n",
       "adhd053509                                 2423                    1640   \n",
       "\n",
       "            anatomy_lh_entorhinal_area  anatomy_lh_fusiform_area  ...  \\\n",
       "subject_id                                                        ...   \n",
       "adhd317934                         508                      3996  ...   \n",
       "adhd291243                         414                      2777  ...   \n",
       "adhd484859                         446                      3449  ...   \n",
       "adhd570109                         499                      3197  ...   \n",
       "adhd053509                         487                      3149  ...   \n",
       "\n",
       "                                                 fmri_basc064  \\\n",
       "subject_id                                                      \n",
       "adhd317934  data/fmri_adhd/basc064/adhd317934/run_1/adhd31...   \n",
       "adhd291243  data/fmri_adhd/basc064/adhd291243/run_1/adhd29...   \n",
       "adhd484859  data/fmri_adhd/basc064/adhd484859/run_1/adhd48...   \n",
       "adhd570109  data/fmri_adhd/basc064/adhd570109/run_1/adhd57...   \n",
       "adhd053509  data/fmri_adhd/basc064/adhd053509/run_1/adhd05...   \n",
       "\n",
       "                                                 fmri_basc122  \\\n",
       "subject_id                                                      \n",
       "adhd317934  data/fmri_adhd/basc122/adhd317934/run_1/adhd31...   \n",
       "adhd291243  data/fmri_adhd/basc122/adhd291243/run_1/adhd29...   \n",
       "adhd484859  data/fmri_adhd/basc122/adhd484859/run_1/adhd48...   \n",
       "adhd570109  data/fmri_adhd/basc122/adhd570109/run_1/adhd57...   \n",
       "adhd053509  data/fmri_adhd/basc122/adhd053509/run_1/adhd05...   \n",
       "\n",
       "                                                 fmri_basc197  \\\n",
       "subject_id                                                      \n",
       "adhd317934  data/fmri_adhd/basc197/adhd317934/run_1/adhd31...   \n",
       "adhd291243  data/fmri_adhd/basc197/adhd291243/run_1/adhd29...   \n",
       "adhd484859  data/fmri_adhd/basc197/adhd484859/run_1/adhd48...   \n",
       "adhd570109  data/fmri_adhd/basc197/adhd570109/run_1/adhd57...   \n",
       "adhd053509  data/fmri_adhd/basc197/adhd053509/run_1/adhd05...   \n",
       "\n",
       "                                     fmri_craddock_scorr_mean  \\\n",
       "subject_id                                                      \n",
       "adhd317934  data/fmri_adhd/craddock_scorr_mean/adhd317934/...   \n",
       "adhd291243  data/fmri_adhd/craddock_scorr_mean/adhd291243/...   \n",
       "adhd484859  data/fmri_adhd/craddock_scorr_mean/adhd484859/...   \n",
       "adhd570109  data/fmri_adhd/craddock_scorr_mean/adhd570109/...   \n",
       "adhd053509  data/fmri_adhd/craddock_scorr_mean/adhd053509/...   \n",
       "\n",
       "                            fmri_harvard_oxford_cort_prob_2mm  \\\n",
       "subject_id                                                      \n",
       "adhd317934  data/fmri_adhd/harvard_oxford_cort_prob_2mm/ad...   \n",
       "adhd291243  data/fmri_adhd/harvard_oxford_cort_prob_2mm/ad...   \n",
       "adhd484859  data/fmri_adhd/harvard_oxford_cort_prob_2mm/ad...   \n",
       "adhd570109  data/fmri_adhd/harvard_oxford_cort_prob_2mm/ad...   \n",
       "adhd053509  data/fmri_adhd/harvard_oxford_cort_prob_2mm/ad...   \n",
       "\n",
       "                                                    fmri_msdl  \\\n",
       "subject_id                                                      \n",
       "adhd317934  data/fmri_adhd/msdl/adhd317934/run_1/adhd31793...   \n",
       "adhd291243  data/fmri_adhd/msdl/adhd291243/run_1/adhd29124...   \n",
       "adhd484859  data/fmri_adhd/msdl/adhd484859/run_1/adhd48485...   \n",
       "adhd570109  data/fmri_adhd/msdl/adhd570109/run_1/adhd57010...   \n",
       "adhd053509  data/fmri_adhd/msdl/adhd053509/run_1/adhd05350...   \n",
       "\n",
       "                                              fmri_power_2011  \\\n",
       "subject_id                                                      \n",
       "adhd317934  data/fmri_adhd/power_2011/adhd317934/run_1/adh...   \n",
       "adhd291243  data/fmri_adhd/power_2011/adhd291243/run_1/adh...   \n",
       "adhd484859  data/fmri_adhd/power_2011/adhd484859/run_1/adh...   \n",
       "adhd570109  data/fmri_adhd/power_2011/adhd570109/run_1/adh...   \n",
       "adhd053509  data/fmri_adhd/power_2011/adhd053509/run_1/adh...   \n",
       "\n",
       "                                                 fmri_motions  fmri_select  \\\n",
       "subject_id                                                                   \n",
       "adhd317934  data/fmri_adhd/motions/adhd317934/run_1/motion...            1   \n",
       "adhd291243  data/fmri_adhd/motions/adhd291243/run_1/motion...            1   \n",
       "adhd484859  data/fmri_adhd/motions/adhd484859/run_1/motion...            1   \n",
       "adhd570109  data/fmri_adhd/motions/adhd570109/run_1/motion...            1   \n",
       "adhd053509  data/fmri_adhd/motions/adhd053509/run_1/motion...            1   \n",
       "\n",
       "            repetition_time  \n",
       "subject_id                   \n",
       "adhd317934              2.0  \n",
       "adhd291243              2.0  \n",
       "adhd484859              2.0  \n",
       "adhd570109              2.0  \n",
       "adhd053509              2.5  \n",
       "\n",
       "[5 rows x 222 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1 0 1 1 0 1 1 1 1 1 0 0 1 0 0 0 1 0 1 1 0\n",
      " 0]\n"
     ]
    }
   ],
   "source": [
    "print(labels_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/workflow.png\" width=\"100%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The framework is evaluated with a cross-validation approach. The metrics used are the AUC under the ROC and the accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import cross_validate\n",
    "from problem import get_cv\n",
    "\n",
    "def evaluation(X, y):\n",
    "    pipe = make_pipeline(FeatureExtractor(), Classifier())\n",
    "    cv = get_cv(X, y)\n",
    "    results = cross_validate(pipe, X, y, scoring=['roc_auc', 'accuracy'], cv=cv,\n",
    "                             verbose=1, return_train_score=True,\n",
    "                             n_jobs=1)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Simple starting kit: using only anatomical features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### FeatureExtractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The available structural data can be used directly to make some classification. In this regard, we will use a feature extractor (i.e. `FeatureExtractor`). This extractor will only select only the anatomical features, dropping any information regarding the fMRI-based features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.base import TransformerMixin\n",
    "\n",
    "\n",
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def fit(self, X_df, y):\n",
    "        return self\n",
    "\n",
    "    def transform(self, X_df):\n",
    "        # get only the anatomical information\n",
    "        X = X_df[[col for col in X_df.columns if col.startswith('anatomy')]]\n",
    "        return X.drop(columns='anatomy_select')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We propose to use a logistic classifier preceded from a scaler which will remove the mean and standard deviation computed on the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "class Classifier(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.clf = make_pipeline(StandardScaler(), LogisticRegression())\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.clf.fit(X, y)\n",
    "        return self\n",
    "        \n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.clf.predict_proba(X)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Testing the submission"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test locally our pipeline using `evaluation` function that we defined earlier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score ROC-AUC: 0.803 +- 0.007\n",
      "Validation score ROC-AUC: 0.646 +- 0.021 \n",
      "\n",
      "Training score accuracy: 0.732 +- 0.010\n",
      "Validation score accuracy: 0.619 +- 0.027\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:    0.7s finished\n"
     ]
    }
   ],
   "source": [
    "results = evaluation(data_train, labels_train)\n",
    "\n",
    "print(\"Training score ROC-AUC: {:.3f} +- {:.3f}\".format(np.mean(results['train_roc_auc']),\n",
    "                                                        np.std(results['train_roc_auc'])))\n",
    "print(\"Validation score ROC-AUC: {:.3f} +- {:.3f} \\n\".format(np.mean(results['test_roc_auc']),\n",
    "                                                          np.std(results['test_roc_auc'])))\n",
    "\n",
    "print(\"Training score accuracy: {:.3f} +- {:.3f}\".format(np.mean(results['train_accuracy']),\n",
    "                                                         np.std(results['train_accuracy'])))\n",
    "print(\"Validation score accuracy: {:.3f} +- {:.3f}\".format(np.mean(results['test_accuracy']),\n",
    "                                                           np.std(results['test_accuracy'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Going further: using fMRI-derived features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"./img/full_fmri_pipeline.png\" width=\"70%\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the framework illustrated in the figure above, steps 1 to 2 already have been computed during some preprocessing and are the data given during this challenge. Therefore, our feature extractor will implement the step #3 which correspond to the extraction of functional connectivity features. Step 4 is identical to the pipeline presented for the anatomy with a standard scaler followed by a logistic regression classifier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We pointed out that the available feature for fMRI are filename to the time-series. In order to limit the amount of data to be downloaded, we provide a fetcher `fmri_ahdh` in realeases to download only the time-series linked to a specific atlases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the `FeatureExtractor` below, we first only select the filename related to the MSDL time-series data. We create a `FunctionTransformer` which will read on-the-fly the time-series from the CSV file and store them into a numpy array.\n",
    "Those series will be used to extract the functional connectivity matrices which will be used later in the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "\n",
    "\n",
    "def _load_fmri(fmri_filenames):\n",
    "    \"\"\"Load time-series extracted from the fMRI using a specific atlas.\"\"\"\n",
    "    return np.array([pd.read_csv(subject_filename,\n",
    "                                 header=None).values\n",
    "                     for subject_filename in fmri_filenames])\n",
    "\n",
    "\n",
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        # make a transformer which will load the time series and compute the\n",
    "        # connectome matrix\n",
    "        self.transformer_fmri = make_pipeline(\n",
    "            FunctionTransformer(func=_load_fmri, validate=False),\n",
    "            ConnectivityMeasure(kind='tangent', vectorize=True))\n",
    "        \n",
    "    def fit(self, X_df, y):\n",
    "        # get only the time series for the MSDL atlas\n",
    "        fmri_filenames = X_df['fmri_msdl']\n",
    "        self.transformer_fmri.fit(fmri_filenames, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X_df):\n",
    "        fmri_filenames = X_df['fmri_msdl']\n",
    "        return self.transformer_fmri.transform(fmri_filenames)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "\n",
    "\n",
    "class Classifier(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.clf = make_pipeline(StandardScaler(), LogisticRegression(C=1.))\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.clf.fit(X, y)\n",
    "        return self\n",
    "       \n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.clf.predict_proba(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score ROC-AUC: 1.000 +- 0.000\n",
      "Validation score ROC-AUC: 0.626 +- 0.048 \n",
      "\n",
      "Training score accuracy: 1.000 +- 0.000\n",
      "Validation score accuracy: 0.608 +- 0.046\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:   53.1s finished\n"
     ]
    }
   ],
   "source": [
    "results = evaluation(data_train, labels_train)\n",
    "\n",
    "print(\"Training score ROC-AUC: {:.3f} +- {:.3f}\".format(np.mean(results['train_roc_auc']),\n",
    "                                                        np.std(results['train_roc_auc'])))\n",
    "print(\"Validation score ROC-AUC: {:.3f} +- {:.3f} \\n\".format(np.mean(results['test_roc_auc']),\n",
    "                                                          np.std(results['test_roc_auc'])))\n",
    "\n",
    "print(\"Training score accuracy: {:.3f} +- {:.3f}\".format(np.mean(results['train_accuracy']),\n",
    "                                                         np.std(results['train_accuracy'])))\n",
    "print(\"Validation score accuracy: {:.3f} +- {:.3f}\".format(np.mean(results['test_accuracy']),\n",
    "                                                           np.std(results['test_accuracy'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### More elaborate pipeline: combining anatomy and fMRI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This workflow is a combination of the 2 previous workflows. The `FeatureExtractor` is extracting both structural and functional connectivity information and concatenate them. Note that each column will contain in their name either **connectome** or **anatomy** depending of the type of feature. It will be used to train different classifiers later on."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "\n",
    "\n",
    "def _load_fmri(fmri_filenames):\n",
    "    \"\"\"Load time-series extracted from the fMRI using a specific atlas.\"\"\"\n",
    "    return np.array([pd.read_csv(subject_filename,\n",
    "                                 header=None).values\n",
    "                     for subject_filename in fmri_filenames])\n",
    "\n",
    "\n",
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        # make a transformer which will load the time series and compute the\n",
    "        # connectome matrix\n",
    "        self.transformer_fmri = make_pipeline(\n",
    "            FunctionTransformer(func=_load_fmri, validate=False),\n",
    "            ConnectivityMeasure(kind='tangent', vectorize=True))\n",
    "    \n",
    "    def fit(self, X_df, y):\n",
    "        fmri_filenames = X_df['fmri_msdl']\n",
    "        self.transformer_fmri.fit(fmri_filenames, y)\n",
    "        return self\n",
    "\n",
    "    def transform(self, X_df):\n",
    "        fmri_filenames = X_df['fmri_msdl']\n",
    "        X_connectome = self.transformer_fmri.transform(fmri_filenames)\n",
    "        X_connectome = pd.DataFrame(X_connectome, index=X_df.index)\n",
    "        X_connectome.columns = ['connectome_{}'.format(i)\n",
    "                                for i in range(X_connectome.columns.size)]\n",
    "        # get the anatomical information\n",
    "        X_anatomy = X_df[[col for col in X_df.columns\n",
    "                          if col.startswith('anatomy')]]\n",
    "        X_anatomy = X_anatomy.drop(columns='anatomy_select')\n",
    "        # concatenate both matrices\n",
    "        return pd.concat([X_connectome, X_anatomy], axis=1)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a classifier (i.e. a random forest classifier) which will used both connectome and anatomical features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on function fetch_fmri_time_series in module download_data:\n",
      "\n",
      "fetch_fmri_time_series(atlas='all')\n",
      "    Fetch the time-series extracted from the fMRI data using a specific\n",
      "    atlas.\n",
      "    \n",
      "    Parameters\n",
      "    ----------\n",
      "    atlas : string, default='all'\n",
      "        The name of the atlas used during the extraction. The possibilities\n",
      "        are:\n",
      "    \n",
      "        * `'basc064`, `'basc122'`, `'basc197'`: BASC parcellations with 64,\n",
      "        122, and 197 regions [1]_;\n",
      "        * `'craddock_scorr_mean'`: Ncuts parcellations [2]_;\n",
      "        * `'harvard_oxford_cort_prob_2mm'`: Harvard-Oxford anatomical\n",
      "        parcellations;\n",
      "        * `'msdl'`: MSDL functional atlas [3]_;\n",
      "        * `'power_2011'`: Power atlas [4]_.\n",
      "    \n",
      "    Returns\n",
      "    -------\n",
      "    None\n",
      "    \n",
      "    References\n",
      "    ----------\n",
      "    .. [1] Bellec, Pierre, et al. \"Multi-level bootstrap analysis of stable\n",
      "       clusters in resting-state fMRI.\" Neuroimage 51.3 (2010): 1126-1139.\n",
      "    \n",
      "    .. [2] Craddock, R. Cameron, et al. \"A whole brain fMRI atlas generated\n",
      "       via spatially constrained spectral clustering.\" Human brain mapping\n",
      "       33.8 (2012): 1914-1928.\n",
      "    \n",
      "    .. [3] Varoquaux, Gaël, et al. \"Multi-subject dictionary learning to\n",
      "       segment an atlas of brain spontaneous activity.\" Biennial International\n",
      "       Conference on Information Processing in Medical Imaging. Springer,\n",
      "       Berlin, Heidelberg, 2011.\n",
      "    \n",
      "    .. [4] Power, Jonathan D., et al. \"Functional network organization of the\n",
      "       human brain.\" Neuron 72.4 (2011): 665-678.\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/yuliianikolaenko/opt/anaconda3/envs/neurodevelop/lib/python3.7/site-packages/sklearn/externals/joblib/__init__.py:15: DeprecationWarning: sklearn.externals.joblib is deprecated in 0.21 and will be removed in 0.23. Please import this functionality directly from joblib, which can be installed with: pip install joblib. If this warning is raised when loading pickled models, you may need to re-serialize those models with scikit-learn 0.21+.\n",
      "  warnings.warn(msg, category=DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from download_data import fetch_fmri_time_series\n",
    "help(fetch_fmri_time_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading the data from https://zenodo.org/record/3625740/files/msdl.zip ...\n",
      "Decompressing the archive ...\n",
      "Downloading completed ...\n"
     ]
    }
   ],
   "source": [
    "fetch_fmri_time_series(atlas='msdl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "class Classifier(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.clf = RandomForestClassifier(n_estimators=100, n_jobs=-1)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        self.clf.fit(X, y)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.clf.predict(X)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        return self.clf.predict_proba(X)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score ROC-AUC: 1.000 +- 0.000\n",
      "Validation score ROC-AUC: 0.669 +- 0.025 \n",
      "\n",
      "Training score accuracy: 1.000 +- 0.000\n",
      "Validation score accuracy: 0.617 +- 0.014\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  3.4min finished\n"
     ]
    }
   ],
   "source": [
    "results = evaluation(data_train, labels_train)\n",
    "\n",
    "print(\"Training score ROC-AUC: {:.3f} +- {:.3f}\".format(np.mean(results['train_roc_auc']),\n",
    "                                                        np.std(results['train_roc_auc'])))\n",
    "print(\"Validation score ROC-AUC: {:.3f} +- {:.3f} \\n\".format(np.mean(results['test_roc_auc']),\n",
    "                                                          np.std(results['test_roc_auc'])))\n",
    "\n",
    "print(\"Training score accuracy: {:.3f} +- {:.3f}\".format(np.mean(results['train_accuracy']),\n",
    "                                                         np.std(results['train_accuracy'])))\n",
    "print(\"Validation score accuracy: {:.3f} +- {:.3f}\".format(np.mean(results['test_accuracy']),\n",
    "                                                           np.std(results['test_accuracy'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can propose a\n",
    "more complex classifier than the previous one. We will train 2 single classifiers independetly on the sMRI-derived and fMRI-derived features. Then, a meta-classifier will be used to combine both information. We left out some data to be able to train the meta-classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "class Classifier(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.clf_connectome = make_pipeline(StandardScaler(),\n",
    "                                            LogisticRegression(C=1.))\n",
    "        self.clf_anatomy = make_pipeline(StandardScaler(),\n",
    "                                         LogisticRegression(C=1.))\n",
    "        self.meta_clf = LogisticRegression(C=1.)\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X_anatomy = X[[col for col in X.columns if col.startswith('anatomy')]]\n",
    "        X_connectome = X[[col for col in X.columns\n",
    "                          if col.startswith('connectome')]]\n",
    "        train_idx, validation_idx = train_test_split(range(y.size),\n",
    "                                                     test_size=0.33,\n",
    "                                                     shuffle=True,\n",
    "                                                     random_state=42)\n",
    "        X_anatomy_train = X_anatomy.iloc[train_idx]\n",
    "        X_anatomy_validation = X_anatomy.iloc[validation_idx]\n",
    "        X_connectome_train = X_connectome.iloc[train_idx]\n",
    "        X_connectome_validation = X_connectome.iloc[validation_idx]\n",
    "        y_train = y[train_idx]\n",
    "        y_validation = y[validation_idx]\n",
    "\n",
    "        self.clf_connectome.fit(X_connectome_train, y_train)\n",
    "        self.clf_anatomy.fit(X_anatomy_train, y_train)\n",
    "\n",
    "        y_connectome_pred = self.clf_connectome.predict_proba(\n",
    "            X_connectome_validation)\n",
    "        y_anatomy_pred = self.clf_anatomy.predict_proba(\n",
    "            X_anatomy_validation)\n",
    "\n",
    "        self.meta_clf.fit(\n",
    "            np.concatenate([y_connectome_pred, y_anatomy_pred], axis=1),\n",
    "            y_validation)\n",
    "        return self\n",
    "    \n",
    "    def predict(self, X):\n",
    "        X_anatomy = X[[col for col in X.columns if col.startswith('anatomy')]]\n",
    "        X_connectome = X[[col for col in X.columns\n",
    "                          if col.startswith('connectome')]]\n",
    "\n",
    "        y_anatomy_pred = self.clf_anatomy.predict_proba(X_anatomy)\n",
    "        y_connectome_pred = self.clf_connectome.predict_proba(X_connectome)\n",
    "\n",
    "        return self.meta_clf.predict(\n",
    "            np.concatenate([y_connectome_pred, y_anatomy_pred], axis=1))\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X_anatomy = X[[col for col in X.columns if col.startswith('anatomy')]]\n",
    "        X_connectome = X[[col for col in X.columns\n",
    "                          if col.startswith('connectome')]]\n",
    "\n",
    "        y_anatomy_pred = self.clf_anatomy.predict_proba(X_anatomy)\n",
    "        y_connectome_pred = self.clf_connectome.predict_proba(X_connectome)\n",
    "\n",
    "        return self.meta_clf.predict_proba(\n",
    "            np.concatenate([y_connectome_pred, y_anatomy_pred], axis=1))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score ROC-AUC: 0.892 +- 0.023\n",
      "Validation score ROC-AUC: 0.661 +- 0.021 \n",
      "\n",
      "Training score accuracy: 0.810 +- 0.030\n",
      "Validation score accuracy: 0.622 +- 0.024\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed:  3.0min finished\n"
     ]
    }
   ],
   "source": [
    "results = evaluation(data_train, labels_train)\n",
    "\n",
    "print(\"Training score ROC-AUC: {:.3f} +- {:.3f}\".format(np.mean(results['train_roc_auc']),\n",
    "                                                        np.std(results['train_roc_auc'])))\n",
    "print(\"Validation score ROC-AUC: {:.3f} +- {:.3f} \\n\".format(np.mean(results['test_roc_auc']),\n",
    "                                                          np.std(results['test_roc_auc'])))\n",
    "\n",
    "print(\"Training score accuracy: {:.3f} +- {:.3f}\".format(np.mean(results['train_accuracy']),\n",
    "                                                         np.std(results['train_accuracy'])))\n",
    "print(\"Validation score accuracy: {:.3f} +- {:.3f}\".format(np.mean(results['test_accuracy']),\n",
    "                                                           np.std(results['test_accuracy'])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## SVM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.base import BaseEstimator, TransformerMixin\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn import preprocessing\n",
    "from nilearn.connectome import ConnectivityMeasure\n",
    "\n",
    "ATLAS = ('msdl', 'basc064', 'basc122', 'basc197',\n",
    "            'harvard_oxford_cort_prob_2mm', 'craddock_scorr_mean',\n",
    "            'power_2011')\n",
    "\n",
    "\n",
    "def _load_fmri(fmri_filenames):\n",
    "    return np.array([\n",
    "        pd.read_csv(subject_filename, header=None).values\n",
    "        for subject_filename in fmri_filenames\n",
    "    ])\n",
    "\n",
    "\n",
    "class FeatureExtractor(BaseEstimator, TransformerMixin):\n",
    "    def __init__(self):\n",
    "        self.transformer_fmri_dict = {\n",
    "            key: make_pipeline(\n",
    "                FunctionTransformer(func=_load_fmri, validate=False),\n",
    "                ConnectivityMeasure(kind='tangent', vectorize=True))\n",
    "            for key in ATLAS\n",
    "        }\n",
    "\n",
    "    def fit(self, X_df, y):\n",
    "        for atlas_name in self.transformer_fmri_dict.keys():\n",
    "            atlas_col_name = 'fmri_' + atlas_name\n",
    "            fmri_filename = X_df[atlas_col_name]\n",
    "            self.transformer_fmri_dict[atlas_name].fit(fmri_filename, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def transform(self, X_df):\n",
    "        X_anatomy = X_df[[\n",
    "            col for col in X_df.columns if col.startswith('anatomy')\n",
    "        ]]\n",
    "        X_anatomy = X_anatomy.drop(columns='anatomy_select')\n",
    "\n",
    "        X_anatomy_column = X_anatomy.columns\n",
    "        X_anatomy_index = X_df.index\n",
    "\n",
    "        min_max_scaler = preprocessing.MinMaxScaler()\n",
    "        X_anatomy_data = min_max_scaler.fit_transform(X_anatomy)\n",
    "        X_anatomy = pd.DataFrame(\n",
    "            data=X_anatomy_data,\n",
    "            index=X_anatomy_index,\n",
    "            columns=X_anatomy_column)\n",
    "\n",
    "        X_atlas_df = pd.DataFrame(index=X_df.index)\n",
    "        for atlas_name in self.transformer_fmri_dict.keys():\n",
    "            atlas_col_name = 'fmri_' + atlas_name\n",
    "            fmri_filename = X_df[atlas_col_name]\n",
    "\n",
    "            X_connectome = self.transformer_fmri_dict[atlas_name].transform(\n",
    "                fmri_filename)\n",
    "            X_connectome = pd.DataFrame(X_connectome, index=X_df.index)\n",
    "            X_connectome.columns = [\n",
    "                atlas_name + '_connectome_{}'.format(i)\n",
    "                for i in range(X_connectome.columns.size)\n",
    "            ]\n",
    "\n",
    "            X_anatomy.columns = [\n",
    "                atlas_name + '_' + col for col in X_anatomy_column\n",
    "            ]\n",
    "\n",
    "            X_atlas_df = pd.concat([X_atlas_df, X_anatomy, X_connectome],\n",
    "                                   axis=1)\n",
    "\n",
    "        return X_atlas_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.base import BaseEstimator\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "ATLAS = ('msdl', 'basc064', 'basc122', 'basc197',\n",
    "            'harvard_oxford_cort_prob_2mm', 'craddock_scorr_mean',\n",
    "            'power_2011')\n",
    "\n",
    "\n",
    "class Classifier(BaseEstimator):\n",
    "    def __init__(self):\n",
    "        self.base_clf_dict = {key: SVC(probability=True) for key in ATLAS}\n",
    "        self.clf = LogisticRegression(C=1.)\n",
    "        self.svc_parameters = [{\n",
    "            'kernel': ['rbf'],\n",
    "            'gamma': [1e-3, 1e-4],\n",
    "            'C': [0.5, 1, 10, 100, 1000]\n",
    "        }, {\n",
    "            'kernel': ['linear'],\n",
    "            'C': [0.5, 1, 10, 100, 1000]\n",
    "        }]\n",
    "\n",
    "    def _clf_data(self, X):\n",
    "        X_atlas_dict = {\n",
    "            key: X[[col for col in X.columns if col.startswith(key)]].values\n",
    "            for key in ATLAS\n",
    "        }\n",
    "        X_meta_clf = None\n",
    "        for key in self.base_clf_dict.keys():\n",
    "            base_predict_pro = self.base_clf_dict[key].predict_proba(\n",
    "                X_atlas_dict[key])\n",
    "\n",
    "            if X_meta_clf is None:\n",
    "                X_meta_clf = base_predict_pro\n",
    "            else:\n",
    "                X_meta_clf = np.concatenate([X_meta_clf, base_predict_pro],\n",
    "                                            axis=1)\n",
    "\n",
    "        return X_meta_clf\n",
    "\n",
    "    def _grid_search(self, estimator, parameters, X, y):\n",
    "        grid_search = GridSearchCV(estimator, parameters, n_jobs=-1, verbose=1)\n",
    "        grid_search.fit(X, y)\n",
    "\n",
    "        return grid_search.best_params_\n",
    "\n",
    "    def fit(self, X, y):\n",
    "        X_atlas_dict = {\n",
    "            key: X[[col for col in X.columns if col.startswith(key)]].values\n",
    "            for key in ATLAS\n",
    "        }\n",
    "        for key, val in X_atlas_dict.items():\n",
    "            best_params = self._grid_search(self.base_clf_dict[key],\n",
    "                                            self.svc_parameters, val, y)\n",
    "            self.base_clf_dict[key].set_params(**best_params)\n",
    "\n",
    "            self.base_clf_dict[key].fit(val, y)\n",
    "\n",
    "        X_clf = self._clf_data(X)\n",
    "        self.clf.fit(X_clf, y)\n",
    "\n",
    "        return self\n",
    "\n",
    "    def predict(self, X):\n",
    "        X_clf = self._clf_data(X)\n",
    "\n",
    "        return self.clf.predict(X_clf)\n",
    "\n",
    "    def predict_proba(self, X):\n",
    "        X_clf = self._clf_data(X)\n",
    "\n",
    "        return self.clf.predict_proba(X_clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    5.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    8.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   31.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    5.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    4.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    8.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   29.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    4.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  2.0min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    4.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   11.9s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   29.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    5.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    9.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   19.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed: 28.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    5.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  3.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  3.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    5.1s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    8.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   29.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    4.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    5.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    8.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   29.7s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    4.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  2.2min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  2.6min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    5.2s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    8.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   28.3s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  1.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    4.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  2.4min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    4.5s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    7.8s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:   27.6s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  1.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:    4.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  2.1min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 15 candidates, totalling 45 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 8 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  45 out of  45 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score ROC-AUC: 1.000 +- 0.000\n",
      "Validation score ROC-AUC: 0.755 +- 0.050 \n",
      "\n",
      "Training score accuracy: 1.000 +- 0.000\n",
      "Validation score accuracy: 0.691 +- 0.041\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   8 out of   8 | elapsed: 202.1min finished\n"
     ]
    }
   ],
   "source": [
    "results = evaluation(data_train, labels_train)\n",
    "\n",
    "print(\"Training score ROC-AUC: {:.3f} +- {:.3f}\".format(np.mean(results['train_roc_auc']),\n",
    "                                                        np.std(results['train_roc_auc'])))\n",
    "print(\"Validation score ROC-AUC: {:.3f} +- {:.3f} \\n\".format(np.mean(results['test_roc_auc']),\n",
    "                                                          np.std(results['test_roc_auc'])))\n",
    "\n",
    "print(\"Training score accuracy: {:.3f} +- {:.3f}\".format(np.mean(results['train_accuracy']),\n",
    "                                                         np.std(results['train_accuracy'])))\n",
    "print(\"Validation score accuracy: {:.3f} +- {:.3f}\".format(np.mean(results['test_accuracy']),\n",
    "                                                           np.std(results['test_accuracy'])))"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Raw Cell Format",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
